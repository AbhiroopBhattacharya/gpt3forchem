{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try inverse design of photoswitches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's still use the five bins we had for the forward task and then see if we ca generate valid SMILES.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gpt3forchem.data import get_photoswitch_data\n",
    "from gpt3forchem.input import create_single_property_forward_prompts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gpt3forchem.api_wrappers import (\n",
    "    fine_tune,\n",
    "    query_gpt3,\n",
    "    extract_prediction,\n",
    "    ensemble_fine_tune,\n",
    "    multiple_query_gpt3,\n",
    ")\n",
    "import time\n",
    "from pycm import ConfusionMatrix\n",
    "from gpt3forchem.baselines import GPRBaseline, compute_fragprints\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_photoswitch_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to get the composition of the molecule to avoid that it doesn't only remember the wavelength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "mol = Chem.AddHs(Chem.MolFromSmiles(\"C(=O)O\"))\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(atom.GetSymbol() for atom in mol.GetAtoms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           C[N]1N=NC(=N1)N=NC2=CC=CC=C2\n",
       "1                           C[N]1C=NC(=N1)N=NC2=CC=CC=C2\n",
       "2                           C[N]1C=CC(=N1)N=NC2=CC=CC=C2\n",
       "3                        C[N]1C=C(C)C(=N1)N=NC2=CC=CC=C2\n",
       "4                           C[N]1C=C(C=N1)N=NC2=CC=CC=C2\n",
       "                             ...                        \n",
       "387    OC%38=C%39N=CC=CC%39=C(/N=N/C%40=NC%41=CC(C)=C...\n",
       "388    OC%42=C%43N=CC=CC%43=C(/N=N/C%44=NC%45=CC=CC=C...\n",
       "389    N#CC1C(SC(/N=N/C2=NC(C=CC([N+]([O-])=O)=C3)=C3...\n",
       "390    N#Cc5c(c6ccc(Cl)cc6)c(/N=N/C7=NC(C=CC([N+]([O-...\n",
       "391    N#CC9C(SC(/N=N/C%10=NC(C=CC([N+]([O-])=O)=C%11...\n",
       "Name: SMILES, Length: 392, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"SMILES\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the best case for \"inverse\" design is to use the $\\pi$-$\\pi^*$ transition and the $n$-$\\pi^*$ transition.\n",
    "We simply will train on both and see if it can then answer a corresponding prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_w_n_pistar = \"What is a molecule with a pi-pi* transition wavelength of {} nm and n-pi* transition wavelength of {} nm###\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"What is a molecule with a pi-pi* transition wavelength of {} nm###\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TEMPLATE = \"{}@@@\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "completions = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    if np.isnan(row[\"E isomer n-pi* wavelength in nm\"]):\n",
    "        prompt = PROMPT_TEMPLATE.format(row[\"E isomer pi-pi* wavelength in nm\"])\n",
    "    else:\n",
    "        prompt = PROMPT_TEMPLATE_w_n_pistar.format(\n",
    "            row[\"E isomer pi-pi* wavelength in nm\"],\n",
    "            row[\"E isomer n-pi* wavelength in nm\"],\n",
    "        )\n",
    "\n",
    "    completion = COMPLETION_TEMPLATE.format(row[\"SMILES\"])\n",
    "    prompts.append(prompt)\n",
    "    completions.append(completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.DataFrame({\"prompt\": prompts, \"completion\": completions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts, test_prompts = train_test_split(prompts, test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_prompts)\n",
    "\n",
    "filename_base = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "train_filename = (\n",
    "    f\"run_files/{filename_base}_train_prompts_photoswitch_inverse_{train_size}.jsonl\"\n",
    ")\n",
    "test_filename = (\n",
    "    f\"run_files/{filename_base}_test_prompts_photoswitch_inverse_{train_size}.jsonl\"\n",
    ")\n",
    "\n",
    "\n",
    "train_prompts.to_json(train_filename, orient=\"records\", lines=True)\n",
    "test_prompts.to_json(test_filename, orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from run_files/2022-09-01-22-40-59_train_prompts_photoswitch_inverse_372.jsonl: file-14E8ycJFulEto46gTf4pP61K\n",
      "Uploaded file from run_files/2022-09-01-22-40-59_test_prompts_photoswitch_inverse_372.jsonl: file-ac3IcG3mrSZAOO2V7cHsJLC2\n",
      "Created fine-tune: ft-ZH0U9kB3bF3ktLgCbn6xI51Y\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-09-01 22:41:15] Created fine-tune: ft-ZH0U9kB3bF3ktLgCbn6xI51Y\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-ZH0U9kB3bF3ktLgCbn6xI51Y\n",
      "\n",
      " \n",
      "Upload progress:   0%|          | 0.00/57.8k [00:00<?, ?it/s]\n",
      "Upload progress: 100%|██████████| 57.8k/57.8k [00:00<00:00, 29.1Mit/s]\n",
      "\n",
      "Upload progress:   0%|          | 0.00/3.13k [00:00<?, ?it/s]\n",
      "Upload progress: 100%|██████████| 3.13k/3.13k [00:00<00:00, 4.66Mit/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fine_tune(train_filename, valid_file=test_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_1 = query_gpt3(\n",
    "    \"ada:ft-lsmoepfl-2022-09-01-21-01-50\", test_prompts, max_tokens=80, temperature=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_15 = query_gpt3(\n",
    "    \"ada:ft-lsmoepfl-2022-09-01-21-01-50\", test_prompts, max_tokens=80, temperature=1.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a molecule pi-pi* transition wavelength of 321.0 nm and n-pi* transition wavelength of 424.0 nm###'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts.iloc[0][\"prompt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_argmax = completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>rate of thermal isomerisation from Z-E in s-1</th>\n",
       "      <th>Solvent used for thermal isomerisation rates</th>\n",
       "      <th>Z PhotoStationaryState</th>\n",
       "      <th>E PhotoStationaryState</th>\n",
       "      <th>E isomer pi-pi* wavelength in nm</th>\n",
       "      <th>Extinction</th>\n",
       "      <th>E isomer n-pi* wavelength in nm</th>\n",
       "      <th>Extinction coefficient in M-1 cm-1</th>\n",
       "      <th>...</th>\n",
       "      <th>CAM-B3LYP/6-31G** DFT E isomer n-pi* wavelength in nm</th>\n",
       "      <th>CAM-B3LYP/6-31G** DFT Z isomer pi-pi* wavelength in nm</th>\n",
       "      <th>CAM-B3LYP/6-31G** DFT Z isomer n-pi* wavelength in nm</th>\n",
       "      <th>BHLYP/6-31G* DFT E isomer pi-pi* wavelength in nm</th>\n",
       "      <th>BHLYP/6-31G* DFT E isomer n-pi* wavelength in nm</th>\n",
       "      <th>BHLYP/6-31G* Z isomer pi-pi* wavelength in nm</th>\n",
       "      <th>BHLYP/6-31G* DFT Z isomer n-pi* wavelength in nm</th>\n",
       "      <th>name</th>\n",
       "      <th>selfies</th>\n",
       "      <th>wavelength_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, SMILES, rate of thermal isomerisation from Z-E in s-1, Solvent used for thermal isomerisation rates, Z PhotoStationaryState, E PhotoStationaryState, E isomer pi-pi* wavelength in nm, Extinction, E isomer n-pi* wavelength in nm, Extinction coefficient in M-1 cm-1, Z isomer pi-pi* wavelength in nm, Extinction.1, Z isomer n-pi* wavelength in nm, Extinction coefficient in M-1 cm-1.1, Wiberg index, E-Z irradiation wavelength in nm, Z-E irradiation wavelength, Irradiation solvent, PBE0 DFT E isomer pi-pi* wavelength in nm, PBE0 DFT E isomer n-pi* wavelength in nm, PBE0 DFT Z isomer pi-pi* wavelength in nm, PBE0 DFT Z isomer n-pi* wavelength in nm, TPSSh/6-31G** DFT E isomer pi-pi* wavelength in nm, TPSSh/6-31G** DFT E isomer n-pi* wavelength in nm, TPSSh/6-31G** DFT Z isomer pi-pi* wavelength in nm, TPSSh/6-31G** DFT Z isomer n-pi* wavelength in nm, CAM-B3LYP/6-31G** DFT E isomer pi-pi* wavelength in nm, CAM-B3LYP/6-31G** DFT E isomer n-pi* wavelength in nm, CAM-B3LYP/6-31G** DFT Z isomer pi-pi* wavelength in nm, CAM-B3LYP/6-31G** DFT Z isomer n-pi* wavelength in nm, BHLYP/6-31G* DFT E isomer pi-pi* wavelength in nm, BHLYP/6-31G* DFT E isomer n-pi* wavelength in nm, BHLYP/6-31G* Z isomer pi-pi* wavelength in nm, BHLYP/6-31G* DFT Z isomer n-pi* wavelength in nm, name, selfies, wavelength_cat]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 37 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"SMILES\"] == \"C1=CC=C(/N=N/C2=CC=C(NCCC#N)C=C2)C=C1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [<OpenAIObject at 0x2a1eb1180> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 0,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC1=C(/N=N/C2=CC(F)=CC=C2)C(C)=NO1@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1ea7d60> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 1,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"[H]C6=CC=C(N=C(N=NC7=CC=CC=C7S8S9)T8)C8=C6@@@N#N=C7@@@N#C[H]C=C8@@@C8@@@C@@@C9@@@C@@@C@@@C@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1ea7a90> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 2,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CCN(CCC#N)C(C=C%22)=CC=C%22/N=N/C%23=CC(OC)=CC=C%23@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1ea75e0> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 3,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"FC1=CC=CC(F)=C1/N=N/C2=CC=CC=C2@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e42f40> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 4,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC(C=C(N(CCC#N)CCO)C=C1)=C1/N=N/C2=CC=CC=C2[N+]([O-])=O@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8dcc0> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 5,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"BrC1=CC(/N=N/C2=CC=C(NCCC#N)C=C2)=CC=C1@@@N0C=CC(C)=C1@@@N0C=C(Cl)C=C1@@@OCC@@@N0O@@@C(C=C1)=O@@@O\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8d130> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 6,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC1=C(C(C)=NN1)/N=N/C2=CC(C(F)(F)F)=CC=C2@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8d040> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 7,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC(N(CCC#N)CCC#N)=CC=C/N=N/C%11=CC=C(C(F)(F)F)C=C%11@@@@@@CC=C([N+]([O-])=O)C=C%11@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e47220> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 8,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC1=NOC(C)=C1/N=N/C2=CC=C(Cl)C=C2@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e47090> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 9,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"FC1=CC=CC=C1/N=N/C2=CC=CC=C2@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\n\\n@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8e360> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 10,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC1=CC=C(/N=N/C2=CC=C(C)C=C2)C=C1@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8e450> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 11,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC(C=C1)=CC=C1/N=N/C2=CC=C(C#N)C=C2@@@@@@[N+]([O-])=O@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8e540> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 12,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"[H]C%11=CC([N+]([O-])=O)=CC(C#N)=C%11/N=N/C%12=CC([H])=C(C=C%12OC)N(CC)CC@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@C%13\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8e5e0> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 13,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CC(C=C(N(CCC#N)CCC#N)C=C1)=C1/N=N/C2=CC(K)=CC=C2Cl@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8e680> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 14,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"R`C(C=C1)=CC=C1N=NC2=NNC=C2@@@@@@N#O=OC@@@@@@N#S@@@@@CC=CC=C2@@@@@@C9[N+]([O-])=O@@@@@@C9@@@@@CC@@@@@@C\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8e950> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 15,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"NC(C=C1)=CC=C1N=NC2=NNC=C2@@@@@@N#N#N##C=C1.#N#C=C1@@@@@@C#N#C=CC=C1@@@@@@C#N#C=C1@@@@@@C#N#C=C1\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8ecc0> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 16,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"Clc1nnc(n1)N=Nc1c([nH]c2c1cccc2)c1ccccc1@@@@@@Nc1ccnnc1@@@@@@Clc1ccccc1@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8ee00> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 17,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"1N#CC([N+]([O-])=O)=CC(C#N)=C1/N=N/C2=CC([H])=C(C=C2[H])N(CC)CC@@@@@@C1=C2@@@C=C(C=C1)N(CC)CC@@@@@@C\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8eea0> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 18,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"NC1=CC=C(/N=N/C2=CC=C(NCCC#N)C=C2)C=C1@@@N@@@N@@@C@C(C#N)=C1@@@C@@@@@@C#N@@@CC@@@C#N@@@C@C@@@@@@C#\"\n",
       "  },\n",
       "  <OpenAIObject at 0x2a1e8ef40> JSON: {\n",
       "    \"finish_reason\": \"length\",\n",
       "    \"index\": 19,\n",
       "    \"logprobs\": null,\n",
       "    \"text\": \"CSc1nnc(s1)N=Nc1c(C)n(c2c1cccc2)C@@@C(C=C1)N(cc1)CC@@@C@@@C@@@C@@@C@@@C@@@C@@@C@@@C@@@C@@@C@@@C@@@C\"\n",
       "  }]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train models that can predict the wavelengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragprints = compute_fragprints(data[\"SMILES\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "2022-09-02 07:56:44.010873: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.03669 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 39.794   │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02808 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "pi_pi_star_model = GPRBaseline()\n",
    "pi_pi_star_model.fit(fragprints, data[\"E isomer pi-pi* wavelength in nm\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/pi_pi_star_model.joblib']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pi_pi_star_model, \"../models/pi_pi_star_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  1.87032 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 35.2361  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.11178 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "n_pi_star_model = GPRBaseline()\n",
    "n_pi_star_model.fit(\n",
    "    fragprints[data[~data[\"E isomer n-pi* wavelength in nm\"].isna()].index.values],\n",
    "    data[\"E isomer n-pi* wavelength in nm\"].values[\n",
    "        data[~data[\"E isomer n-pi* wavelength in nm\"].isna()].index.values\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/n_pi_star_model.joblib']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(n_pi_star_model, \"../models/n_pi_star_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(smiles):\n",
    "    fragprints = compute_fragprints([smiles])\n",
    "    return (\n",
    "        pi_pi_star_model.predict(fragprints)[0],\n",
    "        n_pi_star_model.predict(fragprints)[0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([390.91004025]), array([446.54990223]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"C1=CC=C(/N=N/C2=CC=C(NCCC#N)C=C2)C=C1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a molecule pi-pi* transition wavelength of 404.0 nm###'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts[\"prompt\"].values[-2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now do a more systematic analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how well it does in generating SMILES of photoswitches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt3forchem.output import (\n",
    "    is_valid_smiles,\n",
    "    predict_photoswitch,\n",
    "    is_string_in_training_data,\n",
    ")\n",
    "from gpt3forchem.api_wrappers import extract_inverse_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles = (\n",
    "    train_prompts[\"completion\"].apply(lambda x: x.replace(\"@@@\", \"\")).to_list()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_predictions = [\n",
    "    extract_inverse_prediction(completions_argmax, i)\n",
    "    for i in range(len(completions_argmax[\"choices\"]))\n",
    "]\n",
    "t_05_predictions = [\n",
    "    extract_inverse_prediction(completions_05, i)\n",
    "    for i in range(len(completions_05[\"choices\"]))\n",
    "]\n",
    "t_1_predictions = [\n",
    "    extract_inverse_prediction(completions_1, i)\n",
    "    for i in range(len(completions_1[\"choices\"]))\n",
    "]\n",
    "t_15_predictions = [\n",
    "    extract_inverse_prediction(completions_15, i)\n",
    "    for i in range(len(completions_15[\"choices\"]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:48:28] Explicit valence for atom # 8 O, 3, is greater than permitted\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: [H]C6=CC=C(N=C(N=NC7=CC=CC=C7S8S9)T8)C8=C6\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES '[H]C6=CC=C(N=C(N=NC7=CC=CC=C7S8S9)T8)C8=C6' for input: '[H]C6=CC=C(N=C(N=NC7=CC=CC=C7S8S9)T8)C8=C6'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: CC(C=C(N(CCC#N)CCC#N)C=C1)=C1/N=N/C2=CC(K)=CC=C2Cl\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'CC(C=C(N(CCC#N)CCC#N)C=C1)=C1/N=N/C2=CC(K)=CC=C2Cl' for input: 'CC(C=C(N(CCC#N)CCC#N)C=C1)=C1/N=N/C2=CC(K)=CC=C2Cl'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: R`C(C=C1)=CC=C1N=NC2=NNC=C2\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'R`C(C=C1)=CC=C1N=NC2=NNC=C2' for input: 'R`C(C=C1)=CC=C1N=NC2=NNC=C2'\n",
      "[09:48:28] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 5\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: 1N#CC([N+]([O-])=O)=CC(C#N)=C1/N=N/C2=CC([H])=C(C=C2[H])N(CC)CC\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES '1N#CC([N+]([O-])=O)=CC(C#N)=C1/N=N/C2=CC([H])=C(C=C2[H])N(CC)CC' for input: '1N#CC([N+]([O-])=O)=CC(C#N)=C1/N=N/C2=CC([H])=C(C=C2[H])N(CC)CC'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: CN1C(/N=N/C2=CC=CN=C2)=C(/N=N/C3=CN=CS3C=C(Imes3W)C=O)C=CC(In:hm)=C1\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'CN1C(/N=N/C2=CC=CN=C2)=C(/N=N/C3=CN=CS3C=C(Imes3W)C=O)C=CC(In:hm)=C1' for input: 'CN1C(/N=N/C2=CC=CN=C2)=C(/N=N/C3=CN=CS3C=C(Imes3W)C=O)C=CC(In:hm)=C1'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: CC8=CC(/N=N/C9=CC=\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'CC8=CC(/N=N/C9=CC=' for input: 'CC8=CC(/N=N/C9=CC='\n",
      "[09:48:28] Explicit valence for atom # 2 C, 5, is greater than permitted\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: CC(Cr2Br³nCC)C1=C(/N=N/C2=CC=C(Cl)C=C2)C([ncm])=CC=C1\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'CC(Cr2Br³nCC)C1=C(/N=N/C2=CC=C(Cl)C=C2)C([ncm])=CC=C1' for input: 'CC(Cr2Br³nCC)C1=C(/N=N/C2=CC=C(Cl)C=C2)C([ncm])=CC=C1'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: (CCC)C9=CC=C(/N=N/C1=NC(NC(C)=O)=CC=C1Sty-(OC)C)C=C1\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES '(CCC)C9=CC=C(/N=N/C1=NC(NC(C)=O)=CC=C1Sty-(OC)C)C=C1' for input: '(CCC)C9=CC=C(/N=N/C1=NC(NC(C)=O)=CC=C1Sty-(OC)C)C=C1'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: [H]C4=CC([N+]([O-])=O)=CC(C)M(C\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES '[H]C4=CC([N+]([O-])=O)=CC(C)M(C' for input: '[H]C4=CC([N+]([O-])=O)=CC(C)M(C'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: NC1=CC=CC=C1/N=\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'NC1=CC=CC=C1/N=' for input: 'NC1=CC=CC=C1/N='\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: Cs[nIt]C1=sN\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'Cs[nIt]C1=sN' for input: 'Cs[nIt]C1=sN'\n",
      "[09:48:28] SMILES Parse Error: unclosed ring for input: 'CC20=OC=C(C)C=C1/N=N/C%10=CC(OC)=CC=C%10'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: CC1=C(/N=N/C2=CC=CC(C)=C2)C(Th)=NOONE1\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'CC1=C(/N=N/C2=CC=CC(C)=C2)C(Th)=NOONE1' for input: 'CC1=C(/N=N/C2=CC=CC(C)=C2)C(Th)=NOONE1'\n",
      "[09:48:28] SMILES Parse Error: extra open parentheses for input: 'OC%20=C%21N=CC=CC%21=C(/N=N/C%22=NC'\n",
      "[09:48:28] SMILES Parse Error: unclosed ring for input: '[H]C%17=CC=C([N+]([O-])=O)C=C%17/N=N/C%18=CC=C(C#N)C=C%18S%17'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: QuClC1=CC([N+]([O-])=O)=CC([N+]([O-])=O)=C1/N=N/C2=CC([H])=C(C=C2C)N(CC)CC\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES 'QuClC1=CC([N+]([O-])=O)=CC([N+]([O-])=O)=C1/N=N/C2=CC([H])=C(C=C2C)N(CC)CC' for input: 'QuClC1=CC([N+]([O-])=O)=CC([N+]([O-])=O)=C1/N=N/C2=CC([H])=C(C=C2C)N(CC)CC'\n",
      "[09:48:28] SMILES Parse Error: unclosed ring for input: 'CC2=CC(N(C)=C1C)=C1/N=N/C3=CC=C(N(C)C)C=C3'\n",
      "[09:48:28] SMILES Parse Error: extra open parentheses for input: 'N#CCCNC(C=C1)=CC=C1/N=N/C2=CC=C(O'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: &O{\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES '&O{' for input: '&O{'\n",
      "[09:48:28] SMILES Parse Error: syntax error while parsing: [H]N(CC)C(C=C3)=CC3/N=N/C4=CC([N+]([O-])=O)=CC[N=\n",
      "[09:48:28] SMILES Parse Error: Failed parsing SMILES '[H]N(CC)C(C=C3)=CC3/N=N/C4=CC([N+]([O-])=O)=CC[N=' for input: '[H]N(CC)C(C=C3)=CC3/N=N/C4=CC([N+]([O-])=O)=CC[N='\n",
      "[09:48:28] SMILES Parse Error: extra open parentheses for input: '[H]N(CC'\n"
     ]
    }
   ],
   "source": [
    "argmax_valid_smiles = [is_valid_smiles(smiles) for smiles in argmax_predictions]\n",
    "t_05_valid_smiles = [is_valid_smiles(smiles) for smiles in t_05_predictions]\n",
    "t_1_valid_smiles = [is_valid_smiles(smiles) for smiles in t_1_predictions]\n",
    "t_15_valid_smiles = [is_valid_smiles(smiles) for smiles in t_15_predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions of valid SMILES:\n",
      "========================\n",
      "argmax: 1.0\n",
      "t_05: 0.95\n",
      "t_1: 0.75\n",
      "t_15: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Fractions of valid SMILES:\")\n",
    "print(\"========================\")\n",
    "print(\"argmax: {}\".format(np.mean(argmax_valid_smiles)))\n",
    "print(\"t_05: {}\".format(np.mean(t_05_valid_smiles)))\n",
    "print(\"t_1: {}\".format(np.mean(t_1_valid_smiles)))\n",
    "print(\"t_15: {}\".format(np.mean(t_15_valid_smiles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_smiles_in_train = [\n",
    "    is_string_in_training_data(smiles, train_smiles)\n",
    "    for smiles in np.array(argmax_predictions)[argmax_valid_smiles]\n",
    "]\n",
    "t_05_smiles_in_train = [\n",
    "    is_string_in_training_data(smiles, train_smiles)\n",
    "    for smiles in np.array(t_05_predictions)[t_05_valid_smiles]\n",
    "]\n",
    "t_1_smiles_in_train = [\n",
    "    is_string_in_training_data(smiles, train_smiles)\n",
    "    for smiles in np.array(t_1_predictions)[t_1_valid_smiles]\n",
    "]\n",
    "t_15_smiles_in_train = [\n",
    "    is_string_in_training_data(smiles, train_smiles)\n",
    "    for smiles in np.array(t_15_predictions)[t_15_valid_smiles]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions of valid SMILES in training data:\n",
      "============================================\n",
      "argmax: 1.0\n",
      "t_05: 0.7368421052631579\n",
      "t_1: 0.4\n",
      "t_15: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Fractions of valid SMILES in training data:\")\n",
    "print(\"============================================\")\n",
    "print(\"argmax: {}\".format(np.mean(argmax_smiles_in_train)))\n",
    "print(\"t_05: {}\".format(np.mean(t_05_smiles_in_train)))\n",
    "print(\"t_1: {}\".format(np.mean(t_1_smiles_in_train)))\n",
    "print(\"t_15: {}\".format(np.mean(t_15_smiles_in_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_argmax_smiles = np.array(argmax_predictions)[argmax_valid_smiles]\n",
    "valid_t_05_smiles = np.array(t_05_predictions)[t_05_valid_smiles]\n",
    "valid_t_1_smiles = np.array(t_1_predictions)[t_1_valid_smiles]\n",
    "valid_t_15_smiles = np.array(t_15_predictions)[t_15_valid_smiles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_pi_pi_star, argmax_n_pi_star = predict_photoswitch(valid_argmax_smiles)\n",
    "t_05_pi_pi_star, t_05_n_pi_star = predict_photoswitch(valid_t_05_smiles)\n",
    "t_1_pi_pi_star, t_1_n_pi_star = predict_photoswitch(valid_t_1_smiles)   \n",
    "t_15_pi_pi_star, t_15_n_pi_star = predict_photoswitch(valid_t_15_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a molecule pi-pi* transition wavelength of 321.0 nm and n-pi* transition wavelength of 424.0 nm###'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts[\"prompt\"].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt3forchem.output import get_expected_wavelengths, get_regression_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_pi_pi_star, expected_n_pi_star =[], []\n",
    "\n",
    "for prompt in test_prompts[\"prompt\"].values:\n",
    "    pi_pi_star, n_pi_star = get_expected_wavelengths(prompt)\n",
    "    expected_pi_pi_star.append(pi_pi_star)\n",
    "    expected_n_pi_star.append(n_pi_star)\n",
    "\n",
    "expected_pi_pi_star = np.array(expected_pi_pi_star)\n",
    "expected_n_pi_star = np.array(expected_n_pi_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': 0.3464112321589137,\n",
       " 'max_error': 133.5998863689873,\n",
       " 'mean_absolute_error': 29.93002272620189,\n",
       " 'mean_squared_error': 2051.5808288428584}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_pi_pi_star[argmax_valid_smiles], argmax_pi_pi_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -0.4248960029180302,\n",
       " 'max_error': 146.45797892327198,\n",
       " 'mean_absolute_error': 46.8321830192999,\n",
       " 'mean_squared_error': 4464.479419846363}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_pi_pi_star[t_05_valid_smiles], t_05_pi_pi_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -0.382265511212019,\n",
       " 'max_error': 167.76807688023155,\n",
       " 'mean_absolute_error': 42.85388470075084,\n",
       " 'mean_squared_error': 4690.094456967374}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_pi_pi_star[t_1_valid_smiles], t_1_pi_pi_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -111.15621599913116,\n",
       " 'max_error': 34.993874515941286,\n",
       " 'mean_absolute_error': 31.588074848198374,\n",
       " 'mean_squared_error': 1009.4059439921805}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_pi_pi_star[t_15_valid_smiles], t_15_pi_pi_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_expected_n_pi_star = np.array([n_pi_star is not None for n_pi_star in expected_n_pi_star])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -1.069562347103199,\n",
       " 'max_error': 76.87946170929854,\n",
       " 'mean_absolute_error': 29.75297447286569,\n",
       " 'mean_squared_error': 1595.230154715741}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_n_pi_star[argmax_valid_smiles & has_expected_n_pi_star], argmax_n_pi_star[argmax_valid_smiles & has_expected_n_pi_star])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -0.8245117223890688,\n",
       " 'max_error': 76.87946170929854,\n",
       " 'mean_absolute_error': 28.727677025579123,\n",
       " 'mean_squared_error': 1670.9608158328047}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_n_pi_star[t_05_valid_smiles  & has_expected_n_pi_star], argmax_n_pi_star[t_05_valid_smiles & has_expected_n_pi_star])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': -1.069562347103199,\n",
       " 'max_error': 76.87946170929854,\n",
       " 'mean_absolute_error': 29.75297447286569,\n",
       " 'mean_squared_error': 1595.230154715741}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_regression_metrics(expected_n_pi_star[t_1_valid_smiles  & has_expected_n_pi_star], argmax_n_pi_star[t_1_valid_smiles & has_expected_n_pi_star])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
