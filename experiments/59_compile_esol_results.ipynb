{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob \n",
    "from fastcore.xtras import load_pickle\n",
    "\n",
    "from gpt3forchem.output import get_regression_metrics\n",
    "from gpt3forchem.api_wrappers import extract_prediction\n",
    "\n",
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = glob('results/20221130_esol/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "baselines = []\n",
    "\n",
    "for res in all_res:\n",
    "    res = load_pickle(res)\n",
    "    cm = res['cm']\n",
    "    cm = ConfusionMatrix(list(map(lambda x: str(x).strip(), res['cm'].actual_vector)), list(map(lambda x: str(x).strip(), res['cm'].predict_vector)))\n",
    "    baseline_cm = res['baseline']['cm']\n",
    "    baseline_cm = ConfusionMatrix(list(map(lambda x: str(x).strip(), baseline_cm.actual_vector)), list(map(lambda x: str(x).strip(), baseline_cm.predict_vector)))\n",
    "    metrics.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'accuracy': cm.ACC_Macro,\n",
    "            'f1_macro': cm.F1_Macro,\n",
    "            'f1_micro': cm.F1_Micro\n",
    "        })\n",
    "    baselines.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'accuracy': baseline_cm.ACC_Macro,\n",
    "            'f1_macro': baseline_cm.F1_Macro,\n",
    "            'f1_micro': baseline_cm.F1_Micro  \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = load_pickle(all_res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "baselines = pd.DataFrame(baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "       &     & \\multicolumn{2}{l}{accuracy} & \\multicolumn{2}{l}{f1\\_macro} & \\multicolumn{2}{l}{f1\\_micro} \\\\\n",
      "       &     &     mean &   std &     mean &   std &     mean &   std \\\\\n",
      "representation & train\\_size &          &       &          &       &          &       \\\\\n",
      "\\midrule\n",
      "inchi & 10  &     0.76 &  0.02 &     0.13 &  0.03 &     0.39 &  0.04 \\\\\n",
      "       & 50  &     0.80 &  0.02 &     0.21 &  0.07 &     0.49 &  0.05 \\\\\n",
      "       & 500 &     0.90 &  0.01 &     0.66 &  0.05 &     0.75 &  0.02 \\\\\n",
      "iupac\\_name & 10  &     0.76 &  0.02 &     0.14 &  0.04 &     0.40 &  0.05 \\\\\n",
      "       & 50  &     0.77 &  0.01 &     0.17 &  0.04 &     0.42 &  0.02 \\\\\n",
      "       & 500 &     0.88 &  0.01 &     0.62 &  0.03 &     0.70 &  0.02 \\\\\n",
      "selfies & 10  &     0.78 &  0.03 &     0.17 &  0.06 &     0.44 &  0.07 \\\\\n",
      "       & 50  &     0.80 &  0.02 &     0.22 &  0.04 &     0.49 &  0.05 \\\\\n",
      "       & 500 &     0.89 &  0.01 &     0.64 &  0.04 &     0.71 &  0.03 \\\\\n",
      "smiles & 10  &     0.77 &  0.03 &     0.16 &  0.05 &     0.42 &  0.07 \\\\\n",
      "       & 50  &     0.80 &  0.02 &     0.30 &  0.06 &     0.50 &  0.04 \\\\\n",
      "       & 500 &     0.90 &  0.01 &     0.70 &  0.04 &     0.75 &  0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_65015/3509859209.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(metrics.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(metrics.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{accuracy} & \\multicolumn{2}{l}{f1\\_macro} & \\multicolumn{2}{l}{f1\\_micro} \\\\\n",
      "{} &     mean &   std &     mean &   std &     mean &   std \\\\\n",
      "train\\_size &          &       &          &       &          &       \\\\\n",
      "\\midrule\n",
      "10         &     0.76 &  0.02 &     0.13 &  0.04 &     0.41 &  0.05 \\\\\n",
      "50         &     0.85 &  0.01 &     0.41 &  0.07 &     0.63 &  0.03 \\\\\n",
      "500        &     0.87 &  0.05 &     0.39 &  0.36 &     0.43 &  0.39 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_65015/1482754437.py:1: FutureWarning: ['representation'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  print(baselines.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())\n",
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_65015/1482754437.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(baselines.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(baselines.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_regression = glob('results/20221129_esol_regression/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_regression = []\n",
    "baselines_regression = []\n",
    "\n",
    "for res in all_res_regression:\n",
    "    res = load_pickle(res)\n",
    "    metrics_regression.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'r2': res['metrics']['r2'],\n",
    "            'max_error': res['metrics']['max_error'],\n",
    "            'mean_absolute_error': res['metrics']['mean_absolute_error'],\n",
    "            'mean_squared_error': res['metrics']['mean_squared_error'],\n",
    "            'rmse': res['metrics']['rmse'],\n",
    "        })\n",
    "    baselines_regression.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'r2': res['baseline']['r2'],\n",
    "            'max_error': res['baseline']['max_error'],\n",
    "            'mean_absolute_error': res['baseline']['mean_absolute_error'], \n",
    "            'mean_squared_error': res['baseline']['mean_squared_error'],\n",
    "            'rmse': res['baseline']['rmse'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_regression = pd.DataFrame(metrics_regression)\n",
    "\n",
    "baselines_regression = pd.DataFrame(baselines_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrr}\n",
      "\\toprule\n",
      "       &     & \\multicolumn{2}{l}{r2} & \\multicolumn{2}{l}{max\\_error} & \\multicolumn{2}{l}{mean\\_absolute\\_error} & \\multicolumn{2}{l}{mean\\_squared\\_error} & \\multicolumn{2}{l}{rmse} \\\\\n",
      "       &     &  mean &   std &      mean &   std &                mean &   std &               mean &   std &  mean &   std \\\\\n",
      "representation & train\\_size &       &       &           &       &                     &       &                    &       &       &       \\\\\n",
      "\\midrule\n",
      "inchi & 10  & -0.20 &  0.21 &      6.09 &  0.90 &                1.73 &  0.18 &               4.75 &  0.89 &  2.17 &  0.21 \\\\\n",
      "       & 50  &  0.16 &  0.13 &      5.81 &  0.78 &                1.42 &  0.12 &               3.45 &  0.54 &  1.85 &  0.15 \\\\\n",
      "       & 500 &  0.71 &  0.05 &      4.60 &  1.13 &                0.78 &  0.06 &               1.15 &  0.21 &  1.07 &  0.10 \\\\\n",
      "iupac\\_name & 10  & -0.46 &  0.30 &      5.91 &  0.23 &                1.99 &  0.28 &               5.81 &  1.27 &  2.40 &  0.27 \\\\\n",
      "       & 50  & -0.28 &  0.26 &      8.60 &  0.43 &                1.68 &  0.20 &               5.23 &  1.01 &  2.28 &  0.23 \\\\\n",
      "       & 500 &  0.58 &  0.04 &      5.86 &  0.80 &                0.92 &  0.02 &               1.68 &  0.09 &  1.30 &  0.03 \\\\\n",
      "selfies & 10  & -0.47 &  0.39 &      5.81 &  0.51 &                2.00 &  0.34 &               5.86 &  1.62 &  2.40 &  0.34 \\\\\n",
      "       & 50  & -0.16 &  0.14 &      7.53 &  0.39 &                1.66 &  0.10 &               4.74 &  0.54 &  2.18 &  0.12 \\\\\n",
      "       & 500 &  0.73 &  0.03 &      3.72 &  0.44 &                0.78 &  0.04 &               1.08 &  0.11 &  1.04 &  0.06 \\\\\n",
      "smiles & 10  & -0.21 &  0.27 &      6.50 &  0.63 &                1.73 &  0.21 &               4.81 &  1.09 &  2.18 &  0.24 \\\\\n",
      "       & 50  &  0.04 &  0.15 &      6.74 &  1.14 &                1.50 &  0.11 &               3.90 &  0.63 &  1.97 &  0.16 \\\\\n",
      "       & 500 &  0.81 &  0.02 &      2.80 &  0.21 &                0.66 &  0.03 &               0.74 &  0.06 &  0.86 &  0.04 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_65015/950421529.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(metrics_regression.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(metrics_regression.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{r2} & \\multicolumn{2}{l}{max\\_error} & \\multicolumn{2}{l}{mean\\_absolute\\_error} & \\multicolumn{2}{l}{mean\\_squared\\_error} & \\multicolumn{2}{l}{rmse} \\\\\n",
      "{} &  mean &   std &      mean &   std &                mean &   std &               mean &   std &  mean &   std \\\\\n",
      "train\\_size &       &       &           &       &                     &       &                    &       &       &       \\\\\n",
      "\\midrule\n",
      "10         &  0.01 &  0.03 &      5.66 &  0.25 &                1.55 &  0.02 &               3.74 &  0.07 &  1.93 &  0.02 \\\\\n",
      "50         &  0.60 &  0.03 &      4.28 &  0.30 &                0.94 &  0.04 &               1.55 &  0.14 &  1.24 &  0.06 \\\\\n",
      "500        &  0.89 &  0.01 &      2.28 &  0.60 &                0.50 &  0.01 &               0.45 &  0.03 &  0.67 &  0.02 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_65015/1945525124.py:1: FutureWarning: ['representation'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  print(baselines_regression.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())\n",
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_65015/1945525124.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(baselines_regression.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(baselines_regression.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
