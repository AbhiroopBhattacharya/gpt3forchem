{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob \n",
    "from fastcore.xtras import load_pickle\n",
    "\n",
    "from gpt3forchem.output import get_regression_metrics\n",
    "from gpt3forchem.api_wrappers import extract_prediction\n",
    "from gpt3forchem.helpers import compile_table_row\n",
    "\n",
    "\n",
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = glob('results/20221130_freesolv/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "baselines = []\n",
    "\n",
    "for res in all_res:\n",
    "    res = load_pickle(res)\n",
    "    cm = res['cm']\n",
    "    cm = ConfusionMatrix(list(map(lambda x: str(x).strip(), res['cm'].actual_vector)), list(map(lambda x: str(x).strip(), res['cm'].predict_vector)))\n",
    "    baseline_cm = res['baseline']['cm']\n",
    "    baseline_cm = ConfusionMatrix(list(map(lambda x: str(x).strip(), baseline_cm.actual_vector)), list(map(lambda x: str(x).strip(), baseline_cm.predict_vector)))\n",
    "    metrics.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'acc': cm.ACC_Macro,\n",
    "            'f1_macro': cm.F1_Macro,\n",
    "            'f1_micro': cm.F1_Micro\n",
    "        })\n",
    "    baselines.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'acc': baseline_cm.ACC_Macro,\n",
    "            'f1_macro': baseline_cm.F1_Macro,\n",
    "            'f1_micro': baseline_cm.F1_Micro  \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "baselines = pd.DataFrame(baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_micro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>representation</th>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">smiles</th>\n",
       "      <th>10</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>2</td>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.075424</td>\n",
       "      <td>2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.049497</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                  f1_macro                  \\\n",
       "                            mean       std count      mean       std count   \n",
       "representation train_size                                                    \n",
       "smiles         10          0.830  0.019799     2  0.193592  0.075424     2   \n",
       "               50          0.894       NaN     1  0.364279       NaN     1   \n",
       "\n",
       "                          f1_micro                  \n",
       "                              mean       std count  \n",
       "representation train_size                           \n",
       "smiles         10            0.575  0.049497     2  \n",
       "               50            0.735       NaN     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.groupby(['representation', 'train_size']).agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "       &     & \\multicolumn{2}{l}{acc} & \\multicolumn{2}{l}{f1\\_macro} & \\multicolumn{2}{l}{f1\\_micro} \\\\\n",
      "       &     &  mean &   std &     mean &   std &     mean &   std \\\\\n",
      "representation & train\\_size &       &       &          &       &          &       \\\\\n",
      "\\midrule\n",
      "inchi & 10  &  0.80 &  0.02 &     0.20 &  0.03 &     0.50 &  0.06 \\\\\n",
      "       & 50  &  0.84 &  0.01 &     0.23 &  0.03 &     0.59 &  0.03 \\\\\n",
      "       & 500 &  0.94 &  0.01 &     0.76 &  0.16 &     0.84 &  0.03 \\\\\n",
      "iupac\\_name & 10  &  0.81 &  0.02 &     0.19 &  0.04 &     0.53 &  0.06 \\\\\n",
      "       & 50  &  0.86 &  0.03 &     0.38 &  0.11 &     0.66 &  0.07 \\\\\n",
      "       & 500 &  0.94 &  0.01 &     0.75 &  0.10 &     0.85 &  0.02 \\\\\n",
      "selfies & 10  &  0.79 &  0.04 &     0.19 &  0.06 &     0.48 &  0.10 \\\\\n",
      "       & 50  &  0.86 &  0.03 &     0.25 &  0.07 &     0.65 &  0.09 \\\\\n",
      "       & 500 &  0.93 &  0.01 &     0.72 &  0.17 &     0.83 &  0.04 \\\\\n",
      "smiles & 10  &  0.83 &  0.02 &     0.25 &  0.01 &     0.58 &  0.06 \\\\\n",
      "       & 50  &  0.86 &  0.01 &     0.30 &  0.03 &     0.66 &  0.02 \\\\\n",
      "       & 500 &  0.94 &  0.01 &     0.76 &  0.13 &     0.86 &  0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{acc} & \\multicolumn{2}{l}{f1\\_macro} & \\multicolumn{2}{l}{f1\\_micro} \\\\\n",
      "{} &  mean &   std &     mean &   std &     mean &   std \\\\\n",
      "train\\_size &       &       &          &       &          &       \\\\\n",
      "\\midrule\n",
      "10         &  0.83 &  0.00 &     0.22 &  0.04 &     0.58 &  0.01 \\\\\n",
      "50         &  0.90 &  0.01 &     0.47 &  0.08 &     0.74 &  0.02 \\\\\n",
      "500        &  0.86 &  0.07 &     0.31 &  0.38 &     0.35 &  0.42 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(baselines.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_regression = glob('results/20221129_freesolv_regression/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_regression = []\n",
    "baselines_regression = []\n",
    "\n",
    "for res in all_res_regression:\n",
    "    res = load_pickle(res)\n",
    "    metrics_regression.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'r2': res['metrics']['r2'],\n",
    "            'max_error': res['metrics']['max_error'],\n",
    "            'mean_absolute_error': res['metrics']['mean_absolute_error'],\n",
    "            'mean_squared_error': res['metrics']['mean_squared_error'],\n",
    "            'rmse': res['metrics']['rmse'],\n",
    "        })\n",
    "    baselines_regression.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'r2': res['baseline']['r2'],\n",
    "            'max_error': res['baseline']['max_error'],\n",
    "            'mean_absolute_error': res['baseline']['mean_absolute_error'], \n",
    "            'mean_squared_error': res['baseline']['mean_squared_error'],\n",
    "            'rmse': res['baseline']['rmse'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_regression = pd.DataFrame(metrics_regression)\n",
    "\n",
    "baselines_regression = pd.DataFrame(baselines_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrr}\n",
      "\\toprule\n",
      "       &     & \\multicolumn{2}{l}{r2} & \\multicolumn{2}{l}{max\\_error} & \\multicolumn{2}{l}{mean\\_absolute\\_error} & \\multicolumn{2}{l}{mean\\_squared\\_error} & \\multicolumn{2}{l}{rmse} \\\\\n",
      "       &     &  mean &   std &      mean &   std &                mean &   std &               mean &   std &  mean &   std \\\\\n",
      "representation & train\\_size &       &       &           &       &                     &       &                    &       &       &       \\\\\n",
      "\\midrule\n",
      "inchi & 10  & -0.22 &  0.11 &     20.21 &  2.34 &                3.14 &  0.17 &              18.34 &  1.38 &  4.28 &  0.16 \\\\\n",
      "       & 50  & -0.05 &  0.12 &     18.26 &  0.54 &                2.85 &  0.15 &              15.40 &  1.59 &  3.92 &  0.20 \\\\\n",
      "       & 500 &  0.62 &  0.04 &     15.47 &  2.49 &                1.41 &  0.10 &               5.94 &  0.79 &  2.43 &  0.16 \\\\\n",
      "iupac\\_name & 10  & -0.31 &  0.21 &     18.03 &  3.30 &                3.43 &  0.31 &              19.64 &  3.23 &  4.42 &  0.38 \\\\\n",
      "       & 50  &  0.06 &  0.11 &     18.16 &  0.69 &                2.79 &  0.18 &              13.90 &  1.51 &  3.72 &  0.21 \\\\\n",
      "       & 500 &  0.74 &  0.09 &     10.09 &  5.30 &                1.18 &  0.06 &               4.14 &  1.59 &  2.01 &  0.36 \\\\\n",
      "selfies & 10  & -0.09 &  0.18 &     19.09 &  1.96 &                2.97 &  0.21 &              16.32 &  2.22 &  4.03 &  0.27 \\\\\n",
      "       & 50  &  0.14 &  0.08 &     16.48 &  2.72 &                2.68 &  0.15 &              12.64 &  1.09 &  3.55 &  0.16 \\\\\n",
      "       & 500 &  0.69 &  0.08 &     12.02 &  3.17 &                1.25 &  0.11 &               4.78 &  1.46 &  2.17 &  0.32 \\\\\n",
      "smiles & 10  & -0.19 &  0.16 &     19.90 &  2.22 &                3.15 &  0.32 &              17.88 &  2.62 &  4.22 &  0.30 \\\\\n",
      "       & 50  &  0.08 &  0.10 &     18.52 &  1.04 &                2.69 &  0.14 &              13.39 &  1.33 &  3.66 &  0.18 \\\\\n",
      "       & 500 &  0.78 &  0.06 &     10.03 &  3.93 &                1.06 &  0.09 &               3.43 &  1.12 &  1.83 &  0.31 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_regression.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{r2} & \\multicolumn{2}{l}{max\\_error} & \\multicolumn{2}{l}{mean\\_absolute\\_error} & \\multicolumn{2}{l}{mean\\_squared\\_error} & \\multicolumn{2}{l}{rmse} \\\\\n",
      "{} &  mean &   std &      mean &   std &                mean &   std &               mean &   std &  mean &   std \\\\\n",
      "train\\_size &       &       &           &       &                     &       &                    &       &       &       \\\\\n",
      "\\midrule\n",
      "10         &  0.13 &  0.05 &     20.27 &  0.60 &                2.71 &  0.07 &              13.93 &  0.34 &  3.73 &  0.05 \\\\\n",
      "50         &  0.69 &  0.04 &     10.60 &  2.43 &                1.60 &  0.03 &               4.81 &  0.54 &  2.19 &  0.12 \\\\\n",
      "500        &  0.91 &  0.01 &      4.36 &  1.26 &                0.86 &  0.06 &               1.39 &  0.24 &  1.17 &  0.11 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(baselines_regression.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
