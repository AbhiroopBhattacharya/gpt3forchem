{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob \n",
    "from fastcore.xtras import load_pickle\n",
    "\n",
    "from gpt3forchem.output import get_regression_metrics\n",
    "from gpt3forchem.api_wrappers import extract_prediction\n",
    "\n",
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = glob('results/20221130_lipophilicity/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "baselines = []\n",
    "\n",
    "for res in all_res:\n",
    "    res = load_pickle(res)\n",
    "    cm = res['cm']\n",
    "    cm = ConfusionMatrix(list(map(lambda x: str(x).strip(), res['cm'].actual_vector)), list(map(lambda x: str(x).strip(), res['cm'].predict_vector)))\n",
    "    baseline_cm = res['baseline']['cm']\n",
    "    baseline_cm = ConfusionMatrix(list(map(lambda x: str(x).strip(), baseline_cm.actual_vector)), list(map(lambda x: str(x).strip(), baseline_cm.predict_vector)))\n",
    "    metrics.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'accuracy': cm.ACC_Macro,\n",
    "            'f1_macro': cm.F1_Macro,\n",
    "            'f1_micro': cm.F1_Micro\n",
    "        })\n",
    "    baselines.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'accuracy': baseline_cm.ACC_Macro,\n",
    "            'f1_macro': baseline_cm.F1_Macro,\n",
    "            'f1_micro': baseline_cm.F1_Micro  \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "baselines = pd.DataFrame(baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "       &     & \\multicolumn{2}{l}{accuracy} & \\multicolumn{2}{l}{f1\\_macro} & \\multicolumn{2}{l}{f1\\_micro} \\\\\n",
      "       &     &     mean &   std &     mean &   std &     mean &   std \\\\\n",
      "representation & train\\_size &          &       &          &       &          &       \\\\\n",
      "\\midrule\n",
      "inchi & 10  &     0.76 &  0.01 &     0.14 &  0.04 &     0.37 &  0.02 \\\\\n",
      "       & 50  &     0.75 &  0.01 &     0.13 &  0.03 &     0.38 &  0.02 \\\\\n",
      "       & 500 &     0.76 &  0.01 &     0.22 &  0.02 &     0.39 &  0.02 \\\\\n",
      "iupac\\_name & 10  &     0.76 &  0.06 &     0.12 &  0.03 &     0.25 &  0.07 \\\\\n",
      "       & 50  &     0.73 &  0.02 &     0.12 &  0.04 &     0.33 &  0.06 \\\\\n",
      "       & 500 &     0.75 &  0.02 &     0.24 &  0.04 &     0.37 &  0.04 \\\\\n",
      "selfies & 10  &     0.74 &  0.03 &     0.11 &  0.03 &     0.32 &  0.04 \\\\\n",
      "       & 50  &     0.75 &  0.01 &     0.15 &  0.03 &     0.38 &  0.01 \\\\\n",
      "       & 500 &     0.76 &  0.01 &     0.23 &  0.04 &     0.39 &  0.02 \\\\\n",
      "smiles & 10  &     0.76 &  0.03 &     0.20 &  0.05 &     0.38 &  0.05 \\\\\n",
      "       & 50  &     0.77 &  0.02 &     0.17 &  0.05 &     0.40 &  0.02 \\\\\n",
      "       & 500 &     0.75 &  0.01 &     0.28 &  0.02 &     0.38 &  0.01 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{accuracy} & \\multicolumn{2}{l}{f1\\_macro} & \\multicolumn{2}{l}{f1\\_micro} \\\\\n",
      "{} &     mean &   std &     mean &   std &     mean &   std \\\\\n",
      "train\\_size &          &       &          &       &          &       \\\\\n",
      "\\midrule\n",
      "10         &     0.75 &  0.00 &     0.11 &  0.00 &     0.38 &  0.00 \\\\\n",
      "50         &     0.75 &  0.01 &     0.15 &  0.04 &     0.37 &  0.01 \\\\\n",
      "500        &     0.79 &  0.01 &     0.29 &  0.04 &     0.46 &  0.02 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(baselines.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_regression = glob('results/20221129_lipophilicity_regression/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_regression = []\n",
    "baselines_regression = []\n",
    "\n",
    "for res in all_res_regression:\n",
    "    res = load_pickle(res)\n",
    "    metrics_regression.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'r2': res['metrics']['r2'],\n",
    "            'max_error': res['metrics']['max_error'],\n",
    "            'mean_absolute_error': res['metrics']['mean_absolute_error'],\n",
    "            'mean_squared_error': res['metrics']['mean_squared_error'],\n",
    "            'rmse': res['metrics']['rmse'],\n",
    "        })\n",
    "    baselines_regression.append(\n",
    "        {\n",
    "            'train_size': res['train_size'],\n",
    "            'representation': res['representation'],\n",
    "            'r2': res['baseline']['r2'],\n",
    "            'max_error': res['baseline']['max_error'],\n",
    "            'mean_absolute_error': res['baseline']['mean_absolute_error'], \n",
    "            'mean_squared_error': res['baseline']['mean_squared_error'],\n",
    "            'rmse': res['baseline']['rmse'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_regression = pd.DataFrame(metrics_regression)\n",
    "\n",
    "baselines_regression = pd.DataFrame(baselines_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrr}\n",
      "\\toprule\n",
      "       &     & \\multicolumn{2}{l}{r2} & \\multicolumn{2}{l}{max\\_error} & \\multicolumn{2}{l}{mean\\_absolute\\_error} & \\multicolumn{2}{l}{mean\\_squared\\_error} & \\multicolumn{2}{l}{rmse} \\\\\n",
      "       &     &  mean &   std &      mean &   std &                mean &   std &               mean &   std &  mean &   std \\\\\n",
      "representation & train\\_size &       &       &           &       &                     &       &                    &       &       &       \\\\\n",
      "\\midrule\n",
      "inchi & 10  & -0.60 &  0.15 &      4.17 &  0.75 &                1.26 &  0.08 &               2.47 &  0.34 &  1.57 &  0.11 \\\\\n",
      "       & 50  & -0.19 &  0.30 &      3.86 &  0.42 &                1.09 &  0.15 &               1.87 &  0.49 &  1.36 &  0.18 \\\\\n",
      "       & 500 & -0.04 &  0.10 &      3.55 &  0.20 &                1.02 &  0.05 &               1.61 &  0.17 &  1.27 &  0.07 \\\\\n",
      "iupac\\_name & 10  & -0.29 &  0.28 &      4.25 &  0.48 &                1.12 &  0.13 &               1.98 &  0.48 &  1.40 &  0.17 \\\\\n",
      "       & 50  & -0.47 &  0.25 &      4.66 &  0.55 &                1.20 &  0.13 &               2.30 &  0.41 &  1.51 &  0.13 \\\\\n",
      "       & 500 &  0.04 &  0.00 &      3.58 &  0.28 &                0.97 &  0.03 &               1.48 &  0.09 &  1.22 &  0.04 \\\\\n",
      "selfies & 10  & -0.50 &  0.34 &      3.60 &  0.63 &                1.22 &  0.14 &               2.31 &  0.59 &  1.51 &  0.19 \\\\\n",
      "       & 50  & -0.28 &  0.25 &      3.72 &  0.53 &                1.15 &  0.11 &               2.01 &  0.38 &  1.41 &  0.13 \\\\\n",
      "       & 500 &  0.03 &  0.02 &      3.66 &  0.25 &                0.96 &  0.02 &               1.48 &  0.06 &  1.21 &  0.02 \\\\\n",
      "smiles & 10  & -0.45 &  0.41 &      4.24 &  0.40 &                1.18 &  0.18 &               2.23 &  0.65 &  1.48 &  0.21 \\\\\n",
      "       & 50  & -0.14 &  0.15 &      3.79 &  0.28 &                1.08 &  0.08 &               1.80 &  0.20 &  1.34 &  0.08 \\\\\n",
      "       & 500 &  0.05 &  0.05 &      3.59 &  0.37 &                0.94 &  0.03 &               1.42 &  0.12 &  1.19 &  0.05 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_regression.groupby(['representation', 'train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{r2} & \\multicolumn{2}{l}{max\\_error} & \\multicolumn{2}{l}{mean\\_absolute\\_error} & \\multicolumn{2}{l}{mean\\_squared\\_error} & \\multicolumn{2}{l}{rmse} \\\\\n",
      "{} &  mean &   std &      mean &   std &                mean &   std &               mean &   std &  mean &   std \\\\\n",
      "train\\_size &       &       &           &       &                     &       &                    &       &       &       \\\\\n",
      "\\midrule\n",
      "10         & -0.09 &  0.06 &      3.82 &  0.17 &                1.01 &  0.05 &               1.69 &  0.19 &  1.30 &  0.07 \\\\\n",
      "50         &  0.07 &  0.07 &      3.26 &  0.30 &                0.96 &  0.06 &               1.43 &  0.16 &  1.19 &  0.07 \\\\\n",
      "500        &  0.38 &  0.02 &      3.11 &  0.44 &                0.79 &  0.03 &               1.00 &  0.05 &  1.00 &  0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(baselines_regression.groupby(['train_size']).agg(['mean', 'std']).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
