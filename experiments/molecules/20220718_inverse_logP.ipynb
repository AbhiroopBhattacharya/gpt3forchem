{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict molecules given a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['science', 'nature'])\n",
    "from pycm import ConfusionMatrix\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from gpt3forchem.molecules.data import get_data\n",
    "from gpt3forchem.molecules.constants import TARGETS, FEATURES, CAT_TARGETS\n",
    "from gpt3forchem.molecules.create_prompts import create_inverse_prompts\n",
    "from gpt3forchem.fine_tune import fine_tune\n",
    "from gpt3forchem.query_model import query_gpt3, extract_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "data = data.loc[(data[\"logP\"] >= -5) & (data[\"logP\"] <= 15)]\n",
    "data['logP_binned'] = pd.qcut(data['logP'], 5, labels=np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ranges =pd.qcut(data['logP'], 5, labels=np.arange(5), retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = {i: (ranges[i], ranges[i + 1]) for i in range(len(ranges) - 1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (-4.989399999999997, 0.098),\n",
       " 1: (0.098, 1.7063),\n",
       " 2: (1.7063, 2.8406000000000025),\n",
       " 3: (2.8406000000000025, 4.168000000000004),\n",
       " 4: (4.168000000000004, 14.856799999999968)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data, train_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10695 train points and 7131 test points\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_df)\n",
    "test_size = len(test_df)\n",
    "print(f\"{len(train_df)} train points and {len(test_df)} test points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts = create_inverse_prompts(train_df)\n",
    "test_prompts = create_inverse_prompts(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_lengths = []\n",
    "\n",
    "for i, row in train_prompts.iterrows(): \n",
    "    completion_lengths.append(len(row['completion']))\n",
    "\n",
    "completion_lengths = np.array(completion_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4037., 3925., 1719.,  545.,  220.,   99.,   71.,   41.,   10.,\n",
       "          12.]),\n",
       " array([  5. ,  33.7,  62.4,  91.1, 119.8, 148.5, 177.2, 205.9, 234.6,\n",
       "        263.3, 292. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(completion_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10679"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7118"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_base = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "train_filename = f\"run_files/{filename_base}_train_inverse_prompts_mols_{train_size}.jsonl\"\n",
    "valid_filename = f\"run_files/{filename_base}_valid_inverse_prompts_mols_{test_size}.jsonl\"\n",
    "# to save money, just run a small valid frame\n",
    "valid_small_filename = f\"run_files/{filename_base}_validsmall_inverse_prompts_mols_{test_size}.jsonl\"\n",
    "train_prompts.to_json(train_filename, orient=\"records\", lines=True)\n",
    "test_prompts.to_json(valid_filename, orient=\"records\", lines=True)\n",
    "test_prompts.sample(100).to_json(valid_small_filename, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 1.64M/1.64M [00:00<00:00, 613Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from run_files/2022-07-18-14-18-55_train_inverse_prompts_mols_10695.jsonl: file-PpfZPEaSoOcFVOc32DQoFiiD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 14.9k/14.9k [00:00<00:00, 17.9Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from run_files/2022-07-18-14-18-55_validsmall_inverse_prompts_mols_7131.jsonl: file-H0uhTXZkP1YDe4H2x9TlH9pc\n",
      "Created fine-tune: ft-s3nM44v1Sd8Yu6uW5IBopCcY\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-07-18 14:19:00] Created fine-tune: ft-s3nM44v1Sd8Yu6uW5IBopCcY\n",
      "[2022-07-18 14:19:10] Fine-tune costs $1.19\n",
      "[2022-07-18 14:19:10] Fine-tune enqueued. Queue number: 0\n",
      "[2022-07-18 14:19:11] Fine-tune started\n",
      "[2022-07-18 14:23:16] Completed epoch 1/4\n",
      "[2022-07-18 14:27:02] Completed epoch 2/4\n",
      "[2022-07-18 14:30:49] Completed epoch 3/4\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-s3nM44v1Sd8Yu6uW5IBopCcY\n",
      "\n",
      "Fine-tune ft-s3nM44v1Sd8Yu6uW5IBopCcY has the status \"running\" and will not be logged\n",
      "🎉 wandb sync completed successfully\n"
     ]
    }
   ],
   "source": [
    "fine_tune(train_filename, valid_small_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-07-18 14:19:00] Created fine-tune: ft-s3nM44v1Sd8Yu6uW5IBopCcY\n",
      "[2022-07-18 14:19:10] Fine-tune costs $1.19\n",
      "[2022-07-18 14:19:10] Fine-tune enqueued. Queue number: 0\n",
      "[2022-07-18 14:19:11] Fine-tune started\n",
      "[2022-07-18 14:23:16] Completed epoch 1/4\n",
      "[2022-07-18 14:27:02] Completed epoch 2/4\n",
      "[2022-07-18 14:30:49] Completed epoch 3/4\n",
      "[2022-07-18 14:34:37] Completed epoch 4/4\n",
      "[2022-07-18 14:34:58] Uploaded model: ada:ft-epfl-2022-07-18-12-34-58\n",
      "[2022-07-18 14:34:59] Uploaded result file: file-tHQw6rvj5QvzHsv04YJdN387\n",
      "[2022-07-18 14:34:59] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded 🎉\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m ada:ft-epfl-2022-07-18-12-34-58 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "! openai api fine_tunes.follow -i ft-s3nM44v1Sd8Yu6uW5IBopCcY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_files/2022-07-18-14-18-55_valid_inverse_prompts_mols_7131.jsonl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = pd.read_json(valid_filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a molecule with 8 C, 6 H, 0 O, 1 N, 0 P, 0 S and a logP of 2?###'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts['prompt'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = query_gpt3(\"ada:ft-epfl-2022-07-18-12-34-58\", test_prompts.iloc[:5], max_tokens=350)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt3forchem.molecules.analysis import analyze_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'What is a molecule with 11 C, 16 H, 0 O, 0 N, 0 P, 0 S and a logP of 3?###',\n",
       " 'completion': ' C1=CC=C(C=C1)C(C)C@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@',\n",
       " 'smiles': 'C1=CC=C(C=C1)C(C)C',\n",
       " 'predicted_log_p': 2.8100000000000014,\n",
       " 'requested_log_p': 3,\n",
       " 'requested_composition': {'C': 1, 'H': 6, 'O': 0, 'N': 0, 'P': 0, 'S': 0},\n",
       " 'distance': 0.03060000000000107,\n",
       " 'distances': [8, 6],\n",
       " 'min': 6,\n",
       " 'max': 8,\n",
       " 'mean': 7.0,\n",
       " 'expected_len': 7,\n",
       " 'found_len': 21}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_completion(test_prompts.iloc[4]['prompt'], completions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
