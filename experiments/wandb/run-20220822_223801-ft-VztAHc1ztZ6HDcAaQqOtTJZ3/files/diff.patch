diff --git a/experiments/wandb/latest-run b/experiments/wandb/latest-run
index 3286af4..c8245b7 120000
--- a/experiments/wandb/latest-run
+++ b/experiments/wandb/latest-run
@@ -1 +1 @@
-run-20220822_104328-ft-fARz0PHXfc4Dp43XiAh173PQ
\ No newline at end of file
+run-20220822_223801-ft-VztAHc1ztZ6HDcAaQqOtTJZ3
\ No newline at end of file
diff --git a/gpt3forchem/_modidx.py b/gpt3forchem/_modidx.py
index eefae73..5f14d56 100644
--- a/gpt3forchem/_modidx.py
+++ b/gpt3forchem/_modidx.py
@@ -63,4 +63,13 @@ d = { 'settings': { 'allowed_cell_metadata_keys': '',
                                    'gpt3forchem.input.decode_categorical_value': 'https://kjappelbaum.github.io/gpt3forchem/input.html#decode_categorical_value',
                                    'gpt3forchem.input.encode_categorical_value': 'https://kjappelbaum.github.io/gpt3forchem/input.html#encode_categorical_value',
                                    'gpt3forchem.input.get_polymer_composition_dict': 'https://kjappelbaum.github.io/gpt3forchem/input.html#get_polymer_composition_dict'},
-            'gpt3forchem.output': {'gpt3forchem.output.string_distances': 'https://kjappelbaum.github.io/gpt3forchem/output.html#string_distances'}}}
\ No newline at end of file
+            'gpt3forchem.output': { 'gpt3forchem.output.composition_mismatch': 'https://kjappelbaum.github.io/gpt3forchem/output.html#composition_mismatch',
+                                    'gpt3forchem.output.convert2smiles': 'https://kjappelbaum.github.io/gpt3forchem/output.html#convert2smiles',
+                                    'gpt3forchem.output.get_completion_composition': 'https://kjappelbaum.github.io/gpt3forchem/output.html#get_completion_composition',
+                                    'gpt3forchem.output.get_num_monomer': 'https://kjappelbaum.github.io/gpt3forchem/output.html#get_num_monomer',
+                                    'gpt3forchem.output.get_prompt_compostion': 'https://kjappelbaum.github.io/gpt3forchem/output.html#get_prompt_compostion',
+                                    'gpt3forchem.output.get_prompt_data': 'https://kjappelbaum.github.io/gpt3forchem/output.html#get_prompt_data',
+                                    'gpt3forchem.output.get_regression_metrics': 'https://kjappelbaum.github.io/gpt3forchem/output.html#get_regression_metrics',
+                                    'gpt3forchem.output.get_target': 'https://kjappelbaum.github.io/gpt3forchem/output.html#get_target',
+                                    'gpt3forchem.output.string2performance': 'https://kjappelbaum.github.io/gpt3forchem/output.html#string2performance',
+                                    'gpt3forchem.output.string_distances': 'https://kjappelbaum.github.io/gpt3forchem/output.html#string_distances'}}}
\ No newline at end of file
diff --git a/gpt3forchem/output.py b/gpt3forchem/output.py
index bf421f4..8241efd 100644
--- a/gpt3forchem/output.py
+++ b/gpt3forchem/output.py
@@ -1,7 +1,8 @@
 # AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/04_output.ipynb.
 
 # %% auto 0
-__all__ = ['string_distances']
+__all__ = ['string_distances', 'convert2smiles', 'get_num_monomer', 'get_prompt_compostion', 'get_target', 'get_prompt_data',
+           'get_completion_composition', 'string2performance', 'composition_mismatch', 'get_regression_metrics']
 
 # %% ../notebooks/04_output.ipynb 4
 def string_distances(training_set: Iterable[str], query_string: str):
@@ -35,3 +36,121 @@ def string_distances(training_set: Iterable[str], query_string: str):
 
     return aggregated_distances
 
+
+# %% ../notebooks/04_output.ipynb 7
+def convert2smiles(string):
+    new_encoding = {"A": "[Ta]", "B": "[Tr]", "W": "[W]", "R": "[R]"}
+
+    for k, v in new_encoding.items():
+        string = string.replace(k, v)
+
+    string = string.replace("-", "")
+
+    return string
+
+
+# %% ../notebooks/04_output.ipynb 11
+def get_num_monomer(string, monomer):
+    num = re.findall(f"([\d+]) {monomer}", string)
+    try:
+        num = int(num[0])
+    except Exception:
+        num = 0
+    return num
+
+
+# %% ../notebooks/04_output.ipynb 13
+def get_prompt_compostion(prompt):
+    composition = {}
+
+    for monomer in ["R", "W", "A", "B"]:
+        composition[monomer] = get_num_monomer(prompt, monomer)
+
+    return composition
+
+
+# %% ../notebooks/04_output.ipynb 14
+def get_target(string, target_name="adsorption"):
+    num = re.findall(f"([\d+]) {target_name}", string)
+    return int(num[0])
+
+
+# %% ../notebooks/04_output.ipynb 15
+def get_prompt_data(prompt):
+    composition = get_prompt_compostion(prompt)
+
+    return composition, get_target(prompt)
+
+
+# %% ../notebooks/04_output.ipynb 16
+def get_completion_composition(string):
+    parts = string.split("-")
+    counts = Counter(parts)
+    return dict(counts)
+
+
+# %% ../notebooks/04_output.ipynb 17
+def string2performance(string):
+    # we need to perform a bunch of tasks here:
+    # 1) Featurize
+    # 2) Query the model
+
+    predicted_monomer_sequence = string.split("@")[0].strip()
+    monomer_sq = re.findall("[(R|W|A|B)\-(R|W|A|B)]+", predicted_monomer_sequence)[0]
+    composition = get_completion_composition(monomer_sq)
+    smiles = convert2smiles(predicted_monomer_sequence)
+
+    features = pd.DataFrame(featurize_many([smiles]))
+    prediction = DELTA_G_MODEL.predict(features[FEATURES])
+    return {
+        "monomer_squence": monomer_sq,
+        "composition": composition,
+        "smiles": smiles,
+        "prediction": prediction,
+    }
+
+
+# %% ../notebooks/04_output.ipynb 18
+def composition_mismatch(composition: dict, found: dict):
+    distances = []
+
+    # We also might have the case the there are keys that the input did not contain
+    all_keys = set(composition.keys()) & set(found.keys())
+
+    expected_len = []
+    found_len = []
+
+    for key in all_keys:
+        try:
+            expected = composition[key]
+        except KeyError:
+            expected = 0
+        expected_len.append(expected)
+        try:
+            f = found[key]
+        except KeyError:
+            f = 0
+        found_len.append(f)
+
+        distances.append(np.abs(expected - f))
+
+    expected_len = sum(expected_len)
+    found_len = sum(found_len)
+    return {
+        "distances": distances,
+        "min": np.min(distances),
+        "max": np.max(distances),
+        "mean": np.mean(distances),
+        "expected_len": expected_len,
+        "found_len": found_len,
+    }
+
+
+# %% ../notebooks/04_output.ipynb 19
+def get_regression_metrics(y_true, y_pred):
+    return {
+        "r2": r2_score(y_true, y_pred),
+        "max_error": max_error(y_true, y_pred),
+        "mean_absolute_error": mean_absolute_error(y_true, y_pred),
+        "mean_squared_error": mean_squared_error(y_true, y_pred),
+    }
diff --git a/notebooks/04_output.ipynb b/notebooks/04_output.ipynb
index cd3bc11..6798260 100644
--- a/notebooks/04_output.ipynb
+++ b/notebooks/04_output.ipynb
@@ -11,20 +11,23 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
     "# |hide\n",
     "import re\n",
-    "from collections import defaultdict, Counter\n",
+    "from collections import Counter, defaultdict\n",
     "from typing import Iterable\n",
     "\n",
     "import numpy as np\n",
     "from nbdev.showdoc import *\n",
     "from strsimpy.levenshtein import Levenshtein\n",
     "from strsimpy.longest_common_subsequence import LongestCommonSubsequence\n",
-    "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n"
+    "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n",
+    "\n",
+    "\n",
+    "from sklearn.metrics import r2_score, max_error, mean_absolute_error, mean_squared_error"
    ]
   },
   {
@@ -108,10 +111,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
+    "\n",
     "def convert2smiles(string):\n",
     "    new_encoding = {\"A\": \"[Ta]\", \"B\": \"[Tr]\", \"W\": \"[W]\", \"R\": \"[R]\"}\n",
     "\n",
@@ -159,10 +164,11 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
     "def get_num_monomer(string, monomer):\n",
     "    num = re.findall(f\"([\\d+]) {monomer}\", string)\n",
     "    try:\n",
@@ -198,6 +204,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
     "def get_prompt_compostion(prompt):\n",
     "    composition = {}\n",
     "\n",
@@ -213,6 +220,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
+    "\n",
     "def get_target(string, target_name=\"adsorption\"):\n",
     "    num = re.findall(f\"([\\d+]) {target_name}\", string)\n",
     "    return int(num[0])\n"
@@ -224,6 +233,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
+    "\n",
     "def get_prompt_data(prompt):\n",
     "    composition = get_prompt_compostion(prompt)\n",
     "\n",
@@ -236,6 +247,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
+    "\n",
     "def get_completion_composition(string):\n",
     "    parts = string.split(\"-\")\n",
     "    counts = Counter(parts)\n",
@@ -248,6 +261,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
+    "\n",
     "def string2performance(string):\n",
     "    # we need to perform a bunch of tasks here:\n",
     "    # 1) Featurize\n",
@@ -274,6 +289,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
+    "# |export\n",
+    "\n",
     "def composition_mismatch(composition: dict, found: dict):\n",
     "    distances = []\n",
     "\n",
@@ -309,6 +326,48 @@
     "    }\n"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# |export\n",
+    "\n",
+    "def get_regression_metrics(y_true, y_pred):\n",
+    "    return {\n",
+    "        \"r2\": r2_score(y_true, y_pred),\n",
+    "        \"max_error\": max_error(y_true, y_pred),\n",
+    "        \"mean_absolute_error\": mean_absolute_error(y_true, y_pred),\n",
+    "        \"mean_squared_error\": mean_squared_error(y_true, y_pred),\n",
+    "    }"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 5,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'r2': 1.0,\n",
+       " 'max_error': 0,\n",
+       " 'mean_absolute_error': 0.0,\n",
+       " 'mean_squared_error': 0.0}"
+      ]
+     },
+     "execution_count": 5,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "get_regression_metrics(\n",
+    "    [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]\n",
+    ")"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -319,9 +378,26 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 3.8.13 ('gpt3')",
+   "display_name": "Python 3.9.12 ('gpt3')",
    "language": "python",
    "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.9.13"
+  },
+  "vscode": {
+   "interpreter": {
+    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
+   }
   }
  },
  "nbformat": 4,
