diff --git a/experiments/wandb/latest-run b/experiments/wandb/latest-run
index e4bc54c..9cfccb5 120000
--- a/experiments/wandb/latest-run
+++ b/experiments/wandb/latest-run
@@ -1 +1 @@
-run-20220902_161541-ft-f5xtILIGM6yjvLrj0J1GH5FQ
\ No newline at end of file
+run-20220902_175923-ft-69Qz1KujHgKgrjvDs20RlI9G
\ No newline at end of file
diff --git a/gpt3forchem/api_wrappers.py b/gpt3forchem/api_wrappers.py
index 4c7154f..0061204 100644
--- a/gpt3forchem/api_wrappers.py
+++ b/gpt3forchem/api_wrappers.py
@@ -53,7 +53,7 @@ def fine_tune(
     # ToDo: perhaps also use their Python wrapper? Or call directly via requests? 
     # subprocess is probably the ugliest way to do this, but it works.
     result = subprocess.run(
-        f"openai api fine_tunes.create -t {train_file}  -m {model} --n_epochs {n_epochs} --no-stream" + f" -v {valid_file}" if valid_file is not None else "",
+        f"openai api fine_tunes.create -t {train_file}  -m {model} --n_epochs {n_epochs}" + f" -v {valid_file}" if valid_file is not None else "",
         shell=True,
         stdout=subprocess.PIPE,
         stderr=subprocess.PIPE,
diff --git a/gpt3forchem/output.py b/gpt3forchem/output.py
index fcf423b..47044f4 100644
--- a/gpt3forchem/output.py
+++ b/gpt3forchem/output.py
@@ -1,11 +1,10 @@
 # AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/04_output.ipynb.
 
 # %% auto 0
-__all__ = ['PI_PI_STAR_REGEX', 'N_PI_STAR_REGEX', 'aggregate_array', 'string_distances', 'is_valid_smiles',
-           'is_string_in_training_data', 'get_similarity_to_train_mols', 'convert2smiles', 'get_num_monomer',
-           'get_prompt_compostion', 'get_target', 'get_prompt_data', 'get_completion_composition', 'string2performance',
-           'composition_mismatch', 'get_regression_metrics', 'predict_photoswitch', 'get_expected_wavelengths',
-           'test_inverse_photoswitch']
+__all__ = ['aggregate_array', 'string_distances', 'is_valid_smiles', 'is_string_in_training_data', 'get_similarity_to_train_mols',
+           'convert2smiles', 'get_num_monomer', 'get_prompt_compostion', 'get_target', 'get_prompt_data',
+           'get_completion_composition', 'string2performance', 'composition_mismatch', 'get_regression_metrics',
+           'predict_photoswitch', 'get_expected_wavelengths', 'test_inverse_photoswitch']
 
 # %% ../notebooks/04_output.ipynb 1
 import re
@@ -411,22 +410,3 @@ def test_inverse_photoswitch(
 
     return results
 
-
-# %% ../notebooks/04_output.ipynb 45
-PI_PI_STAR_REGEX = r"pi-pi\* transition wavelength of ([.\d]+) nm"
-N_PI_STAR_REGEX = r"n-pi\* transition wavelength of ([.\d]+) nm"
-
-def get_expected_wavelengths(prompt): 
-    pi_pi_star_match = re.search(PI_PI_STAR_REGEX, prompt)
-    n_pi_star_match = re.search(N_PI_STAR_REGEX, prompt)
-    if pi_pi_star_match:
-        pi_pi_star = float(pi_pi_star_match.group(1))
-    else: 
-        pi_pi_star = None
-    
-    if n_pi_star_match:
-        n_pi_star = float(n_pi_star_match.group(1))
-    else:
-        n_pi_star = None
-
-    return pi_pi_star, n_pi_star
diff --git a/notebooks/01_api_wrappers.ipynb b/notebooks/01_api_wrappers.ipynb
index 324194f..d276d1e 100644
--- a/notebooks/01_api_wrappers.ipynb
+++ b/notebooks/01_api_wrappers.ipynb
@@ -152,7 +152,7 @@
     "    # ToDo: perhaps also use their Python wrapper? Or call directly via requests? \n",
     "    # subprocess is probably the ugliest way to do this, but it works.\n",
     "    result = subprocess.run(\n",
-    "        f\"openai api fine_tunes.create -t {train_file}  -m {model} --n_epochs {n_epochs} --no-stream\" + f\" -v {valid_file}\" if valid_file is not None else \"\",\n",
+    "        f\"openai api fine_tunes.create -t {train_file}  -m {model} --n_epochs {n_epochs}\" + f\" -v {valid_file}\" if valid_file is not None else \"\",\n",
     "        shell=True,\n",
     "        stdout=subprocess.PIPE,\n",
     "        stderr=subprocess.PIPE,\n",
diff --git a/notebooks/04_output.ipynb b/notebooks/04_output.ipynb
index 7abad7c..88c100c 100644
--- a/notebooks/04_output.ipynb
+++ b/notebooks/04_output.ipynb
@@ -11,7 +11,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -739,7 +739,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -758,7 +758,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -767,7 +767,7 @@
        "(404.0, None)"
       ]
      },
-     "execution_count": 3,
+     "execution_count": null,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -778,7 +778,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -787,7 +787,7 @@
        "(321.0, 424.0)"
       ]
      },
-     "execution_count": 4,
+     "execution_count": null,
      "metadata": {},
      "output_type": "execute_result"
     }
