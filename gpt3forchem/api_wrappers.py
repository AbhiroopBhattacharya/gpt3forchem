# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/01_api_wrappers.ipynb.

# %% auto 0
__all__ = ['fine_tune', 'query_gpt3', 'extract_prediction', 'train_test_loop']

# %% ../notebooks/01_api_wrappers.ipynb 2
import subprocess

import openai
import time
import re
from sklearn.model_selection import train_test_split
from pycm import ConfusionMatrix

# %% ../notebooks/01_api_wrappers.ipynb 5
def fine_tune(train_file, valid_file, model: str = "ada"):
    # run the fine tuning
    result = subprocess.run(
        f"openai api fine_tunes.create -t {train_file} -v {valid_file} -m {model}",
        shell=True,
        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
    )
    modelname = re.findall(r'completions.create -m ([\w\d:-]+) -p', result.stdout)[0]
    # sync runs with wandb
    subprocess.run("openai wandb sync -n 1", shell=True)
    return modelname

# %% ../notebooks/01_api_wrappers.ipynb 8
def query_gpt3(model, df, temperature=0, max_tokens=10, sleep=5):
    completions = []
    for i, row in df.iterrows():
        try:
            completion = openai.Completion.create(
                model=model,
                prompt=row["prompt"],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            completions.append(completion)
            time.sleep(sleep)
        except Exception as e:
            print(e)
            print(f"Error on row {i}")
            completions.append(None)

    return completions

# %% ../notebooks/01_api_wrappers.ipynb 9
def extract_prediction(completion):
    return completion["choices"][0]["text"].split("@")[0].strip()


# %% ../notebooks/01_api_wrappers.ipynb 10
def train_test_loop(df, train_size, prompt_create_fn, random_state, stratify=None):

    out = {}
    train, test = train_test_split(df, train_size=train_size, random_state=random_state, stratify=stratify)

    train_prompts = prompt_create_fn(train)
    test_prompts = prompt_create_fn(test)


    train_size  = len(train_prompts)
    test_size = len(test_prompts)

    filename_base = time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())
    train_filename = f"run_files/{filename_base}_train_prompts_polymers_{train_size}.jsonl"
    valid_filename = f"run_files/{filename_base}_valid_prompts_polymers_{test_size}.jsonl"

    train_prompts.to_json(train_filename, orient="records", lines=True)
    test_prompts.to_json(valid_filename, orient="records", lines=True)

    out['train_filename'] = train_filename
    out['valid_filename'] = valid_filename
    out['modelname'] = fine_tune(train_filename, valid_filename)

    test_prompt_subset = test_prompts
    completions = query_gpt3(out['modelname'], test_prompt_subset)

    predictions = [extract_prediction(completion) for completion in completions]
    true = [t.split('@')[0] for t in test_prompt_subset['completion']]

    cm = ConfusionMatrix(true, predictions)

    out['cm'] = cm

    return out
    
