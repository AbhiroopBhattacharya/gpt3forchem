{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp api_wrappers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API wrappers\n",
    "\n",
    "> Helper functions that make it easier to use the OpenAI API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def fine_tune(train_file, valid_file, model: str = \"ada\"):\n",
    "    # run the fine tuning\n",
    "    result = subprocess.run(\n",
    "        f\"openai api fine_tunes.create -t {train_file} -v {valid_file} -m {model}\",\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "    )\n",
    "    modelname = re.findall(r'completions.create -m ([\\w\\d:-]+) -p', result.stdout)[0]\n",
    "    # sync runs with wandb\n",
    "    subprocess.run(\"openai wandb sync -n 1\", shell=True)\n",
    "    return modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stdout_fragment = \"openai api completions.create -m ada:ft-epfl-2022-06-23-09-10-58 -p <YOUR_PROMPT>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def query_gpt3(model, df, temperature=0, max_tokens=10, sleep=5):\n",
    "    completions = []\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            completion = openai.Completion.create(\n",
    "                model=model,\n",
    "                prompt=row[\"prompt\"],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            completions.append(completion)\n",
    "            time.sleep(sleep)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error on row {i}\")\n",
    "            completions.append(None)\n",
    "\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def extract_prediction(completion):\n",
    "    return completion[\"choices\"][0][\"text\"].split(\"@\")[0].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def train_test_loop(df, train_size, prompt_create_fn, random_state, stratify=None, test_subset=None):\n",
    "\n",
    "    out = {}\n",
    "    train, test = train_test_split(df, train_size=train_size, random_state=random_state, stratify=stratify)\n",
    "\n",
    "    train_prompts = prompt_create_fn(train)\n",
    "    test_prompts = prompt_create_fn(test)\n",
    "\n",
    "\n",
    "    train_size  = len(train_prompts)\n",
    "    test_size = len(test_prompts)\n",
    "\n",
    "    filename_base = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "    train_filename = f\"run_files/{filename_base}_train_prompts_polymers_{train_size}.jsonl\"\n",
    "    valid_filename = f\"run_files/{filename_base}_valid_prompts_polymers_{test_size}.jsonl\"\n",
    "\n",
    "    train_prompts.to_json(train_filename, orient=\"records\", lines=True)\n",
    "    test_prompts.to_json(valid_filename, orient=\"records\", lines=True)\n",
    "\n",
    "    out['train_filename'] = train_filename\n",
    "    out['valid_filename'] = valid_filename\n",
    "    out['modelname'] = fine_tune(train_filename, valid_filename)\n",
    "\n",
    "    test_prompt_subset = test_prompts\n",
    "    if test_subset is not None: \n",
    "        test_prompt_subset = test_prompts.sample(test_subset)\n",
    "    completions = query_gpt3(out['modelname'], test_prompt_subset)\n",
    "\n",
    "    ok_completions = [(i, c) for i, c in enumerate(completions) if c is not None]\n",
    "\n",
    "    predictions = [extract_prediction(completion) for _,completion in ok_completions]\n",
    "    true = [int(test_prompt_subset.iloc[i]['completion'].split('@')[0]) for i,_ in ok_completions]\n",
    "    cm = ConfusionMatrix(true, predictions)\n",
    "\n",
    "    out['cm'] = cm\n",
    "\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a4fa60962de90e73b5da8d67a44b01d2de04630d82b94b8db1f727a73d31e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
