{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# |export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Iterable\n",
    "\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from gpflow.mean_functions import Constant\n",
    "from gpflow.utilities import positive, print_summary\n",
    "from gpflow.utilities.ops import broadcasting_elementwise\n",
    "from nbdev.showdoc import *\n",
    "from optuna import create_study\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from optuna.samplers import TPESampler\n",
    "from pycm import ConfusionMatrix\n",
    "from rdkit.Chem import AllChem, Descriptors, MolFromSmiles, MolToSmiles\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from wandb.xgboost import WandbCallback\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from gpt3forchem.data import get_photoswitch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "> Code for baseline models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "class BaseLineModel(ABC):\n",
    "    @abstractmethod\n",
    "    def tune(self, X_train, y_train):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X_train, y_train):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "class XGBClassificationBaseline(BaseLineModel):\n",
    "    def __init__(self, seed, num_trials=100) -> None:\n",
    "        self.seed = seed\n",
    "        self.num_trials = num_trials\n",
    "        self.model = XGBClassifier()\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def tune(self, X_train, y_train):\n",
    "        y_train = self.label_encoder.fit_transform(y_train)\n",
    "\n",
    "        def objective(\n",
    "            trial,\n",
    "            X,\n",
    "            y,\n",
    "            random_state=22,\n",
    "            n_splits=5,\n",
    "            n_jobs=1,\n",
    "            early_stopping_rounds=100,\n",
    "        ):\n",
    "            # XGBoost parameters\n",
    "            params = {\n",
    "                \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 4, 10_000),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "                \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.05),\n",
    "                \"colsample_bytree\": trial.suggest_loguniform(\n",
    "                    \"colsample_bytree\", 0.2, 1\n",
    "                ),\n",
    "                \"subsample\": trial.suggest_loguniform(\"subsample\", 0.00001, 1),\n",
    "                \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 10.0),\n",
    "                \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n",
    "                \"seed\": random_state,\n",
    "                \"n_jobs\": n_jobs,\n",
    "            }\n",
    "\n",
    "            model = XGBClassifier(**params)\n",
    "            pruning_callback = XGBoostPruningCallback(trial, \"validation_0-mlogloss\")\n",
    "            kf = KFold(n_splits=n_splits)\n",
    "            X_values = X.values\n",
    "            y_values = y\n",
    "\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(X_values):\n",
    "                X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n",
    "                y_A, y_B = y_values[train_index], y_values[test_index]\n",
    "\n",
    "                model.fit(\n",
    "                    X_A,\n",
    "                    y_A,\n",
    "                    eval_set=[(X_B, y_B)],\n",
    "                    eval_metric=\"mlogloss\",\n",
    "                    verbose=0,\n",
    "                    callbacks=[pruning_callback],\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                )\n",
    "                y_pred = model.predict(X_B)\n",
    "                scores.append(f1_score(y_pred, y_B, average=\"macro\"))\n",
    "            return np.mean(scores)\n",
    "\n",
    "        sampler = TPESampler(seed=self.seed)\n",
    "        study = create_study(direction=\"maximize\", sampler=sampler)\n",
    "        study.optimize(\n",
    "            lambda trial: objective(\n",
    "                trial,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                random_state=self.seed,\n",
    "                n_splits=5,\n",
    "                n_jobs=-1,\n",
    "                early_stopping_rounds=100,\n",
    "            ),\n",
    "            n_trials=self.num_trials,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "\n",
    "        self.model = XGBClassifier(**study.best_params, callbacks=[WandbCallback()])\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        y_train = self.label_encoder.fit_transform(y_train)\n",
    "        self.model.fit(X_train.values, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.label_encoder.inverse_transform(self.model.predict(X.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class XGBRegressionBaseline(BaseLineModel):\n",
    "    def __init__(self, seed, num_trials=100) -> None:\n",
    "        self.seed = seed\n",
    "        self.num_trials = num_trials\n",
    "        self.model = XGBRegressor()\n",
    "\n",
    "    def tune(self, X_train, y_train):\n",
    "        def objective(\n",
    "            trial,\n",
    "            X,\n",
    "            y,\n",
    "            random_state=22,\n",
    "            n_splits=5,\n",
    "            n_jobs=1,\n",
    "            early_stopping_rounds=50,\n",
    "        ):\n",
    "            # XGBoost parameters\n",
    "            params = {\n",
    "                \"verbosity\": 0,  # 0 (silent) - 3 (debug)\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"n_estimators\": 10000,\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "                \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.005, 0.05),\n",
    "                \"colsample_bytree\": trial.suggest_uniform(\n",
    "                    \"colsample_bytree\", 0.2, 0.6 # note: log uniform was used before\n",
    "                ),\n",
    "                \"subsample\": trial.suggest_uniform(\"subsample\", 0.4, 0.8), # note: log uniform was used before\n",
    "                \"alpha\": trial.suggest_loguniform(\"alpha\", 0.01, 10.0),\n",
    "                \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n",
    "                \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 10.0), # note: this was wrong before (lambda was used as name) \n",
    "                \"min_child_weight\": trial.suggest_loguniform(\n",
    "                    \"min_child_weight\", 10, 1000\n",
    "                ),\n",
    "                \"seed\": random_state,\n",
    "                \"n_jobs\": n_jobs,\n",
    "            }\n",
    "\n",
    "            model = XGBRegressor(**params)\n",
    "            pruning_callback = XGBoostPruningCallback(trial, \"validation_0-rmse\")\n",
    "            kf = KFold(n_splits=n_splits)\n",
    "            X_values = X.values\n",
    "            y_values = y.values\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(X_values):\n",
    "                X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n",
    "                y_A, y_B = y_values[train_index], y_values[test_index]\n",
    "                model.fit(\n",
    "                    X_A,\n",
    "                    y_A,\n",
    "                    eval_set=[(X_B, y_B)],\n",
    "                    eval_metric=\"rmse\",\n",
    "                    verbose=0,\n",
    "                    callbacks=[pruning_callback],\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                )\n",
    "                y_pred = model.predict(X_B)\n",
    "                scores.append(mean_squared_error(y_pred, y_B))\n",
    "            return np.mean(scores)\n",
    "\n",
    "        sampler = TPESampler(seed=self.seed)\n",
    "        study = create_study(direction=\"minimize\", sampler=sampler)\n",
    "        study.optimize(\n",
    "            lambda trial: objective(\n",
    "                trial,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                random_state=self.seed,\n",
    "                n_splits=5,\n",
    "                n_jobs=8,\n",
    "                early_stopping_rounds=100,\n",
    "            ),\n",
    "            n_trials=self.num_trials,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "\n",
    "        self.model = XGBRegressor(**study.best_params)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train.values, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our case studies with \"context\" we also want to create baselines that include some information about the gases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def create_mof_w_context_frame(\n",
    "    df, gas_frame, gases, gas_properties, features, regression: bool = False\n",
    "):\n",
    "    frame = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for gas in gases:\n",
    "            subset = gas_frame[gas_frame[\"formula\"] == gas]\n",
    "            column = subset[\"related_column\"].values[0]\n",
    "            if (not pd.isna(row[column])) and (not \"nan\" in str(row[column]).lower()):\n",
    "\n",
    "                mof_feats = dict(row[features])\n",
    "\n",
    "                if gas_properties:\n",
    "                    gast_feats = {prop: subset[prop].values[0] for prop in gas_properties}\n",
    "                    mof_feats.update(gast_feats)\n",
    "\n",
    "                mof_feats[\"target\"] = row[column]\n",
    "\n",
    "                frame.append(mof_feats)\n",
    "\n",
    "    return pd.DataFrame(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt3forchem.data import get_mof_data, gas_features, preprocess_mof_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/git/kjappelbaum/gpt3forchem/gpt3forchem/data.py:74: DtypeWarning: Columns (23,24,25,26,27,35,36,37,38,39,47,48,49,50,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df =  HashableDataFrame(pd.read_csv(os.path.join(datadir, \"mof.csv\")))\n"
     ]
    }
   ],
   "source": [
    "mof_data = get_mof_data()\n",
    "preprocess_mof_data(mof_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in mof_data.columns if f.startswith('feature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_frame = create_mof_w_context_frame(mof_data, gas_features, ['CO2'], None, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_min</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_max</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_mean</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_std</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_min</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_max</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_mean</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_std</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_persistence_min</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_persistence_max</th>\n",
       "      <th>...</th>\n",
       "      <th>features.amd_all_mean_91</th>\n",
       "      <th>features.amd_all_mean_92</th>\n",
       "      <th>features.amd_all_mean_93</th>\n",
       "      <th>features.amd_all_mean_94</th>\n",
       "      <th>features.amd_all_mean_95</th>\n",
       "      <th>features.amd_all_mean_96</th>\n",
       "      <th>features.amd_all_mean_97</th>\n",
       "      <th>features.amd_all_mean_98</th>\n",
       "      <th>features.amd_all_mean_99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>3.203</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.49660</td>\n",
       "      <td>1.270</td>\n",
       "      <td>3.215</td>\n",
       "      <td>1.766</td>\n",
       "      <td>0.51460</td>\n",
       "      <td>2.400000e-07</td>\n",
       "      <td>1.7770</td>\n",
       "      <td>...</td>\n",
       "      <td>8.410</td>\n",
       "      <td>8.430</td>\n",
       "      <td>8.460</td>\n",
       "      <td>8.490</td>\n",
       "      <td>8.520</td>\n",
       "      <td>8.555</td>\n",
       "      <td>8.586</td>\n",
       "      <td>8.620</td>\n",
       "      <td>8.640</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7026</td>\n",
       "      <td>3.734</td>\n",
       "      <td>1.615</td>\n",
       "      <td>0.38480</td>\n",
       "      <td>1.158</td>\n",
       "      <td>3.768</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0.35840</td>\n",
       "      <td>3.600000e-07</td>\n",
       "      <td>1.5460</td>\n",
       "      <td>...</td>\n",
       "      <td>6.480</td>\n",
       "      <td>6.504</td>\n",
       "      <td>6.527</td>\n",
       "      <td>6.550</td>\n",
       "      <td>6.570</td>\n",
       "      <td>6.594</td>\n",
       "      <td>6.617</td>\n",
       "      <td>6.640</td>\n",
       "      <td>6.664</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7040</td>\n",
       "      <td>3.771</td>\n",
       "      <td>1.518</td>\n",
       "      <td>0.36380</td>\n",
       "      <td>1.273</td>\n",
       "      <td>3.775</td>\n",
       "      <td>1.650</td>\n",
       "      <td>0.30570</td>\n",
       "      <td>6.000000e-08</td>\n",
       "      <td>1.7460</td>\n",
       "      <td>...</td>\n",
       "      <td>6.920</td>\n",
       "      <td>6.945</td>\n",
       "      <td>6.973</td>\n",
       "      <td>6.996</td>\n",
       "      <td>7.020</td>\n",
       "      <td>7.043</td>\n",
       "      <td>7.062</td>\n",
       "      <td>7.086</td>\n",
       "      <td>7.110</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>4.043</td>\n",
       "      <td>1.627</td>\n",
       "      <td>0.45390</td>\n",
       "      <td>1.323</td>\n",
       "      <td>4.074</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.38180</td>\n",
       "      <td>9.000000e-07</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>...</td>\n",
       "      <td>7.140</td>\n",
       "      <td>7.170</td>\n",
       "      <td>7.195</td>\n",
       "      <td>7.220</td>\n",
       "      <td>7.250</td>\n",
       "      <td>7.277</td>\n",
       "      <td>7.300</td>\n",
       "      <td>7.324</td>\n",
       "      <td>7.348</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>4.070</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0.60350</td>\n",
       "      <td>1.269</td>\n",
       "      <td>4.113</td>\n",
       "      <td>1.965</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>3.600000e-07</td>\n",
       "      <td>1.9390</td>\n",
       "      <td>...</td>\n",
       "      <td>7.200</td>\n",
       "      <td>7.223</td>\n",
       "      <td>7.246</td>\n",
       "      <td>7.270</td>\n",
       "      <td>7.293</td>\n",
       "      <td>7.320</td>\n",
       "      <td>7.344</td>\n",
       "      <td>7.367</td>\n",
       "      <td>7.395</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.6826</td>\n",
       "      <td>1.695</td>\n",
       "      <td>1.367</td>\n",
       "      <td>0.38900</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.927</td>\n",
       "      <td>1.560</td>\n",
       "      <td>0.26200</td>\n",
       "      <td>1.879000e-03</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>...</td>\n",
       "      <td>7.492</td>\n",
       "      <td>7.510</td>\n",
       "      <td>7.543</td>\n",
       "      <td>7.562</td>\n",
       "      <td>7.590</td>\n",
       "      <td>7.613</td>\n",
       "      <td>7.645</td>\n",
       "      <td>7.670</td>\n",
       "      <td>7.690</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.6510</td>\n",
       "      <td>3.488</td>\n",
       "      <td>2.379</td>\n",
       "      <td>0.74760</td>\n",
       "      <td>1.693</td>\n",
       "      <td>3.496</td>\n",
       "      <td>2.560</td>\n",
       "      <td>0.67240</td>\n",
       "      <td>1.510000e-03</td>\n",
       "      <td>1.1650</td>\n",
       "      <td>...</td>\n",
       "      <td>8.760</td>\n",
       "      <td>8.800</td>\n",
       "      <td>8.820</td>\n",
       "      <td>8.850</td>\n",
       "      <td>8.860</td>\n",
       "      <td>8.890</td>\n",
       "      <td>8.930</td>\n",
       "      <td>8.950</td>\n",
       "      <td>8.990</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.3870</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.03190</td>\n",
       "      <td>1.782</td>\n",
       "      <td>1.961</td>\n",
       "      <td>1.802</td>\n",
       "      <td>0.05634</td>\n",
       "      <td>2.937000e-01</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>6.740</td>\n",
       "      <td>6.760</td>\n",
       "      <td>6.760</td>\n",
       "      <td>6.790</td>\n",
       "      <td>6.797</td>\n",
       "      <td>6.800</td>\n",
       "      <td>6.816</td>\n",
       "      <td>6.844</td>\n",
       "      <td>6.848</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.4580</td>\n",
       "      <td>1.556</td>\n",
       "      <td>1.545</td>\n",
       "      <td>0.03065</td>\n",
       "      <td>1.838</td>\n",
       "      <td>2.062</td>\n",
       "      <td>1.862</td>\n",
       "      <td>0.07060</td>\n",
       "      <td>2.820000e-01</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>...</td>\n",
       "      <td>6.850</td>\n",
       "      <td>6.900</td>\n",
       "      <td>6.920</td>\n",
       "      <td>6.957</td>\n",
       "      <td>6.960</td>\n",
       "      <td>6.960</td>\n",
       "      <td>6.965</td>\n",
       "      <td>6.996</td>\n",
       "      <td>7.008</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.4820</td>\n",
       "      <td>1.593</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.03467</td>\n",
       "      <td>1.862</td>\n",
       "      <td>2.096</td>\n",
       "      <td>1.889</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>2.700000e-01</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>...</td>\n",
       "      <td>6.880</td>\n",
       "      <td>6.918</td>\n",
       "      <td>6.953</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.016</td>\n",
       "      <td>7.035</td>\n",
       "      <td>7.040</td>\n",
       "      <td>7.047</td>\n",
       "      <td>7.047</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features.phstats_C-H-N-O_dim1_birth_min  \\\n",
       "0                                     0.7010   \n",
       "1                                     0.7026   \n",
       "2                                     0.7040   \n",
       "3                                     0.7010   \n",
       "4                                     0.7010   \n",
       "..                                       ...   \n",
       "165                                   0.6826   \n",
       "166                                   1.6510   \n",
       "167                                   1.3870   \n",
       "168                                   1.4580   \n",
       "169                                   1.4820   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_birth_max  \\\n",
       "0                                      3.203   \n",
       "1                                      3.734   \n",
       "2                                      3.771   \n",
       "3                                      4.043   \n",
       "4                                      4.070   \n",
       "..                                       ...   \n",
       "165                                    1.695   \n",
       "166                                    3.488   \n",
       "167                                    1.488   \n",
       "168                                    1.556   \n",
       "169                                    1.593   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_birth_mean  \\\n",
       "0                                       1.587   \n",
       "1                                       1.615   \n",
       "2                                       1.518   \n",
       "3                                       1.627   \n",
       "4                                       1.850   \n",
       "..                                        ...   \n",
       "165                                     1.367   \n",
       "166                                     2.379   \n",
       "167                                     1.478   \n",
       "168                                     1.545   \n",
       "169                                     1.580   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_birth_std  \\\n",
       "0                                    0.49660   \n",
       "1                                    0.38480   \n",
       "2                                    0.36380   \n",
       "3                                    0.45390   \n",
       "4                                    0.60350   \n",
       "..                                       ...   \n",
       "165                                  0.38900   \n",
       "166                                  0.74760   \n",
       "167                                  0.03190   \n",
       "168                                  0.03065   \n",
       "169                                  0.03467   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_min  \\\n",
       "0                                      1.270   \n",
       "1                                      1.158   \n",
       "2                                      1.273   \n",
       "3                                      1.323   \n",
       "4                                      1.269   \n",
       "..                                       ...   \n",
       "165                                    1.141   \n",
       "166                                    1.693   \n",
       "167                                    1.782   \n",
       "168                                    1.838   \n",
       "169                                    1.862   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_max  \\\n",
       "0                                      3.215   \n",
       "1                                      3.768   \n",
       "2                                      3.775   \n",
       "3                                      4.074   \n",
       "4                                      4.113   \n",
       "..                                       ...   \n",
       "165                                    1.927   \n",
       "166                                    3.496   \n",
       "167                                    1.961   \n",
       "168                                    2.062   \n",
       "169                                    2.096   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_mean  \\\n",
       "0                                       1.766   \n",
       "1                                       1.725   \n",
       "2                                       1.650   \n",
       "3                                       1.750   \n",
       "4                                       1.965   \n",
       "..                                        ...   \n",
       "165                                     1.560   \n",
       "166                                     2.560   \n",
       "167                                     1.802   \n",
       "168                                     1.862   \n",
       "169                                     1.889   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_std  \\\n",
       "0                                    0.51460   \n",
       "1                                    0.35840   \n",
       "2                                    0.30570   \n",
       "3                                    0.38180   \n",
       "4                                    0.58100   \n",
       "..                                       ...   \n",
       "165                                  0.26200   \n",
       "166                                  0.67240   \n",
       "167                                  0.05634   \n",
       "168                                  0.07060   \n",
       "169                                  0.07340   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_persistence_min  \\\n",
       "0                                     2.400000e-07   \n",
       "1                                     3.600000e-07   \n",
       "2                                     6.000000e-08   \n",
       "3                                     9.000000e-07   \n",
       "4                                     3.600000e-07   \n",
       "..                                             ...   \n",
       "165                                   1.879000e-03   \n",
       "166                                   1.510000e-03   \n",
       "167                                   2.937000e-01   \n",
       "168                                   2.820000e-01   \n",
       "169                                   2.700000e-01   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_persistence_max  ...  \\\n",
       "0                                           1.7770  ...   \n",
       "1                                           1.5460  ...   \n",
       "2                                           1.7460  ...   \n",
       "3                                           1.2170  ...   \n",
       "4                                           1.9390  ...   \n",
       "..                                             ...  ...   \n",
       "165                                         0.5635  ...   \n",
       "166                                         1.1650  ...   \n",
       "167                                         0.5740  ...   \n",
       "168                                         0.6040  ...   \n",
       "169                                         0.6140  ...   \n",
       "\n",
       "     features.amd_all_mean_91  features.amd_all_mean_92  \\\n",
       "0                       8.410                     8.430   \n",
       "1                       6.480                     6.504   \n",
       "2                       6.920                     6.945   \n",
       "3                       7.140                     7.170   \n",
       "4                       7.200                     7.223   \n",
       "..                        ...                       ...   \n",
       "165                     7.492                     7.510   \n",
       "166                     8.760                     8.800   \n",
       "167                     6.740                     6.760   \n",
       "168                     6.850                     6.900   \n",
       "169                     6.880                     6.918   \n",
       "\n",
       "     features.amd_all_mean_93  features.amd_all_mean_94  \\\n",
       "0                       8.460                     8.490   \n",
       "1                       6.527                     6.550   \n",
       "2                       6.973                     6.996   \n",
       "3                       7.195                     7.220   \n",
       "4                       7.246                     7.270   \n",
       "..                        ...                       ...   \n",
       "165                     7.543                     7.562   \n",
       "166                     8.820                     8.850   \n",
       "167                     6.760                     6.790   \n",
       "168                     6.920                     6.957   \n",
       "169                     6.953                     7.000   \n",
       "\n",
       "     features.amd_all_mean_95  features.amd_all_mean_96  \\\n",
       "0                       8.520                     8.555   \n",
       "1                       6.570                     6.594   \n",
       "2                       7.020                     7.043   \n",
       "3                       7.250                     7.277   \n",
       "4                       7.293                     7.320   \n",
       "..                        ...                       ...   \n",
       "165                     7.590                     7.613   \n",
       "166                     8.860                     8.890   \n",
       "167                     6.797                     6.800   \n",
       "168                     6.960                     6.960   \n",
       "169                     7.016                     7.035   \n",
       "\n",
       "     features.amd_all_mean_97  features.amd_all_mean_98  \\\n",
       "0                       8.586                     8.620   \n",
       "1                       6.617                     6.640   \n",
       "2                       7.062                     7.086   \n",
       "3                       7.300                     7.324   \n",
       "4                       7.344                     7.367   \n",
       "..                        ...                       ...   \n",
       "165                     7.645                     7.670   \n",
       "166                     8.930                     8.950   \n",
       "167                     6.816                     6.844   \n",
       "168                     6.965                     6.996   \n",
       "169                     7.040                     7.047   \n",
       "\n",
       "     features.amd_all_mean_99  target  \n",
       "0                       8.640     low  \n",
       "1                       6.664     low  \n",
       "2                       7.110     low  \n",
       "3                       7.348     low  \n",
       "4                       7.395     low  \n",
       "..                        ...     ...  \n",
       "165                     7.690     low  \n",
       "166                     8.990     low  \n",
       "167                     6.848    high  \n",
       "168                     7.008    high  \n",
       "169                     7.047    high  \n",
       "\n",
       "[170 rows x 2388 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_frame = create_mof_w_context_frame(mof_data, gas_features, ['CO2'], ['accentric_factor', 'radius'], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_min</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_max</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_mean</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_birth_std</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_min</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_max</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_mean</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_death_std</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_persistence_min</th>\n",
       "      <th>features.phstats_C-H-N-O_dim1_persistence_max</th>\n",
       "      <th>...</th>\n",
       "      <th>features.amd_all_mean_93</th>\n",
       "      <th>features.amd_all_mean_94</th>\n",
       "      <th>features.amd_all_mean_95</th>\n",
       "      <th>features.amd_all_mean_96</th>\n",
       "      <th>features.amd_all_mean_97</th>\n",
       "      <th>features.amd_all_mean_98</th>\n",
       "      <th>features.amd_all_mean_99</th>\n",
       "      <th>accentric_factor</th>\n",
       "      <th>radius</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>3.203</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.49660</td>\n",
       "      <td>1.270</td>\n",
       "      <td>3.215</td>\n",
       "      <td>1.766</td>\n",
       "      <td>0.51460</td>\n",
       "      <td>2.400000e-07</td>\n",
       "      <td>1.7770</td>\n",
       "      <td>...</td>\n",
       "      <td>8.460</td>\n",
       "      <td>8.490</td>\n",
       "      <td>8.520</td>\n",
       "      <td>8.555</td>\n",
       "      <td>8.586</td>\n",
       "      <td>8.620</td>\n",
       "      <td>8.640</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7026</td>\n",
       "      <td>3.734</td>\n",
       "      <td>1.615</td>\n",
       "      <td>0.38480</td>\n",
       "      <td>1.158</td>\n",
       "      <td>3.768</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0.35840</td>\n",
       "      <td>3.600000e-07</td>\n",
       "      <td>1.5460</td>\n",
       "      <td>...</td>\n",
       "      <td>6.527</td>\n",
       "      <td>6.550</td>\n",
       "      <td>6.570</td>\n",
       "      <td>6.594</td>\n",
       "      <td>6.617</td>\n",
       "      <td>6.640</td>\n",
       "      <td>6.664</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7040</td>\n",
       "      <td>3.771</td>\n",
       "      <td>1.518</td>\n",
       "      <td>0.36380</td>\n",
       "      <td>1.273</td>\n",
       "      <td>3.775</td>\n",
       "      <td>1.650</td>\n",
       "      <td>0.30570</td>\n",
       "      <td>6.000000e-08</td>\n",
       "      <td>1.7460</td>\n",
       "      <td>...</td>\n",
       "      <td>6.973</td>\n",
       "      <td>6.996</td>\n",
       "      <td>7.020</td>\n",
       "      <td>7.043</td>\n",
       "      <td>7.062</td>\n",
       "      <td>7.086</td>\n",
       "      <td>7.110</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>4.043</td>\n",
       "      <td>1.627</td>\n",
       "      <td>0.45390</td>\n",
       "      <td>1.323</td>\n",
       "      <td>4.074</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.38180</td>\n",
       "      <td>9.000000e-07</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>...</td>\n",
       "      <td>7.195</td>\n",
       "      <td>7.220</td>\n",
       "      <td>7.250</td>\n",
       "      <td>7.277</td>\n",
       "      <td>7.300</td>\n",
       "      <td>7.324</td>\n",
       "      <td>7.348</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>4.070</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0.60350</td>\n",
       "      <td>1.269</td>\n",
       "      <td>4.113</td>\n",
       "      <td>1.965</td>\n",
       "      <td>0.58100</td>\n",
       "      <td>3.600000e-07</td>\n",
       "      <td>1.9390</td>\n",
       "      <td>...</td>\n",
       "      <td>7.246</td>\n",
       "      <td>7.270</td>\n",
       "      <td>7.293</td>\n",
       "      <td>7.320</td>\n",
       "      <td>7.344</td>\n",
       "      <td>7.367</td>\n",
       "      <td>7.395</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.6826</td>\n",
       "      <td>1.695</td>\n",
       "      <td>1.367</td>\n",
       "      <td>0.38900</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.927</td>\n",
       "      <td>1.560</td>\n",
       "      <td>0.26200</td>\n",
       "      <td>1.879000e-03</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>...</td>\n",
       "      <td>7.543</td>\n",
       "      <td>7.562</td>\n",
       "      <td>7.590</td>\n",
       "      <td>7.613</td>\n",
       "      <td>7.645</td>\n",
       "      <td>7.670</td>\n",
       "      <td>7.690</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.6510</td>\n",
       "      <td>3.488</td>\n",
       "      <td>2.379</td>\n",
       "      <td>0.74760</td>\n",
       "      <td>1.693</td>\n",
       "      <td>3.496</td>\n",
       "      <td>2.560</td>\n",
       "      <td>0.67240</td>\n",
       "      <td>1.510000e-03</td>\n",
       "      <td>1.1650</td>\n",
       "      <td>...</td>\n",
       "      <td>8.820</td>\n",
       "      <td>8.850</td>\n",
       "      <td>8.860</td>\n",
       "      <td>8.890</td>\n",
       "      <td>8.930</td>\n",
       "      <td>8.950</td>\n",
       "      <td>8.990</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.3870</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.03190</td>\n",
       "      <td>1.782</td>\n",
       "      <td>1.961</td>\n",
       "      <td>1.802</td>\n",
       "      <td>0.05634</td>\n",
       "      <td>2.937000e-01</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>6.760</td>\n",
       "      <td>6.790</td>\n",
       "      <td>6.797</td>\n",
       "      <td>6.800</td>\n",
       "      <td>6.816</td>\n",
       "      <td>6.844</td>\n",
       "      <td>6.848</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.4580</td>\n",
       "      <td>1.556</td>\n",
       "      <td>1.545</td>\n",
       "      <td>0.03065</td>\n",
       "      <td>1.838</td>\n",
       "      <td>2.062</td>\n",
       "      <td>1.862</td>\n",
       "      <td>0.07060</td>\n",
       "      <td>2.820000e-01</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>...</td>\n",
       "      <td>6.920</td>\n",
       "      <td>6.957</td>\n",
       "      <td>6.960</td>\n",
       "      <td>6.960</td>\n",
       "      <td>6.965</td>\n",
       "      <td>6.996</td>\n",
       "      <td>7.008</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.4820</td>\n",
       "      <td>1.593</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.03467</td>\n",
       "      <td>1.862</td>\n",
       "      <td>2.096</td>\n",
       "      <td>1.889</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>2.700000e-01</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>...</td>\n",
       "      <td>6.953</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.016</td>\n",
       "      <td>7.035</td>\n",
       "      <td>7.040</td>\n",
       "      <td>7.047</td>\n",
       "      <td>7.047</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.525</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features.phstats_C-H-N-O_dim1_birth_min  \\\n",
       "0                                     0.7010   \n",
       "1                                     0.7026   \n",
       "2                                     0.7040   \n",
       "3                                     0.7010   \n",
       "4                                     0.7010   \n",
       "..                                       ...   \n",
       "165                                   0.6826   \n",
       "166                                   1.6510   \n",
       "167                                   1.3870   \n",
       "168                                   1.4580   \n",
       "169                                   1.4820   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_birth_max  \\\n",
       "0                                      3.203   \n",
       "1                                      3.734   \n",
       "2                                      3.771   \n",
       "3                                      4.043   \n",
       "4                                      4.070   \n",
       "..                                       ...   \n",
       "165                                    1.695   \n",
       "166                                    3.488   \n",
       "167                                    1.488   \n",
       "168                                    1.556   \n",
       "169                                    1.593   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_birth_mean  \\\n",
       "0                                       1.587   \n",
       "1                                       1.615   \n",
       "2                                       1.518   \n",
       "3                                       1.627   \n",
       "4                                       1.850   \n",
       "..                                        ...   \n",
       "165                                     1.367   \n",
       "166                                     2.379   \n",
       "167                                     1.478   \n",
       "168                                     1.545   \n",
       "169                                     1.580   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_birth_std  \\\n",
       "0                                    0.49660   \n",
       "1                                    0.38480   \n",
       "2                                    0.36380   \n",
       "3                                    0.45390   \n",
       "4                                    0.60350   \n",
       "..                                       ...   \n",
       "165                                  0.38900   \n",
       "166                                  0.74760   \n",
       "167                                  0.03190   \n",
       "168                                  0.03065   \n",
       "169                                  0.03467   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_min  \\\n",
       "0                                      1.270   \n",
       "1                                      1.158   \n",
       "2                                      1.273   \n",
       "3                                      1.323   \n",
       "4                                      1.269   \n",
       "..                                       ...   \n",
       "165                                    1.141   \n",
       "166                                    1.693   \n",
       "167                                    1.782   \n",
       "168                                    1.838   \n",
       "169                                    1.862   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_max  \\\n",
       "0                                      3.215   \n",
       "1                                      3.768   \n",
       "2                                      3.775   \n",
       "3                                      4.074   \n",
       "4                                      4.113   \n",
       "..                                       ...   \n",
       "165                                    1.927   \n",
       "166                                    3.496   \n",
       "167                                    1.961   \n",
       "168                                    2.062   \n",
       "169                                    2.096   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_mean  \\\n",
       "0                                       1.766   \n",
       "1                                       1.725   \n",
       "2                                       1.650   \n",
       "3                                       1.750   \n",
       "4                                       1.965   \n",
       "..                                        ...   \n",
       "165                                     1.560   \n",
       "166                                     2.560   \n",
       "167                                     1.802   \n",
       "168                                     1.862   \n",
       "169                                     1.889   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_death_std  \\\n",
       "0                                    0.51460   \n",
       "1                                    0.35840   \n",
       "2                                    0.30570   \n",
       "3                                    0.38180   \n",
       "4                                    0.58100   \n",
       "..                                       ...   \n",
       "165                                  0.26200   \n",
       "166                                  0.67240   \n",
       "167                                  0.05634   \n",
       "168                                  0.07060   \n",
       "169                                  0.07340   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_persistence_min  \\\n",
       "0                                     2.400000e-07   \n",
       "1                                     3.600000e-07   \n",
       "2                                     6.000000e-08   \n",
       "3                                     9.000000e-07   \n",
       "4                                     3.600000e-07   \n",
       "..                                             ...   \n",
       "165                                   1.879000e-03   \n",
       "166                                   1.510000e-03   \n",
       "167                                   2.937000e-01   \n",
       "168                                   2.820000e-01   \n",
       "169                                   2.700000e-01   \n",
       "\n",
       "     features.phstats_C-H-N-O_dim1_persistence_max  ...  \\\n",
       "0                                           1.7770  ...   \n",
       "1                                           1.5460  ...   \n",
       "2                                           1.7460  ...   \n",
       "3                                           1.2170  ...   \n",
       "4                                           1.9390  ...   \n",
       "..                                             ...  ...   \n",
       "165                                         0.5635  ...   \n",
       "166                                         1.1650  ...   \n",
       "167                                         0.5740  ...   \n",
       "168                                         0.6040  ...   \n",
       "169                                         0.6140  ...   \n",
       "\n",
       "     features.amd_all_mean_93  features.amd_all_mean_94  \\\n",
       "0                       8.460                     8.490   \n",
       "1                       6.527                     6.550   \n",
       "2                       6.973                     6.996   \n",
       "3                       7.195                     7.220   \n",
       "4                       7.246                     7.270   \n",
       "..                        ...                       ...   \n",
       "165                     7.543                     7.562   \n",
       "166                     8.820                     8.850   \n",
       "167                     6.760                     6.790   \n",
       "168                     6.920                     6.957   \n",
       "169                     6.953                     7.000   \n",
       "\n",
       "     features.amd_all_mean_95  features.amd_all_mean_96  \\\n",
       "0                       8.520                     8.555   \n",
       "1                       6.570                     6.594   \n",
       "2                       7.020                     7.043   \n",
       "3                       7.250                     7.277   \n",
       "4                       7.293                     7.320   \n",
       "..                        ...                       ...   \n",
       "165                     7.590                     7.613   \n",
       "166                     8.860                     8.890   \n",
       "167                     6.797                     6.800   \n",
       "168                     6.960                     6.960   \n",
       "169                     7.016                     7.035   \n",
       "\n",
       "     features.amd_all_mean_97  features.amd_all_mean_98  \\\n",
       "0                       8.586                     8.620   \n",
       "1                       6.617                     6.640   \n",
       "2                       7.062                     7.086   \n",
       "3                       7.300                     7.324   \n",
       "4                       7.344                     7.367   \n",
       "..                        ...                       ...   \n",
       "165                     7.645                     7.670   \n",
       "166                     8.930                     8.950   \n",
       "167                     6.816                     6.844   \n",
       "168                     6.965                     6.996   \n",
       "169                     7.040                     7.047   \n",
       "\n",
       "     features.amd_all_mean_99  accentric_factor  radius  target  \n",
       "0                       8.640             0.228   1.525     low  \n",
       "1                       6.664             0.228   1.525     low  \n",
       "2                       7.110             0.228   1.525     low  \n",
       "3                       7.348             0.228   1.525     low  \n",
       "4                       7.395             0.228   1.525     low  \n",
       "..                        ...               ...     ...     ...  \n",
       "165                     7.690             0.228   1.525     low  \n",
       "166                     8.990             0.228   1.525     low  \n",
       "167                     6.848             0.228   1.525    high  \n",
       "168                     7.008             0.228   1.525    high  \n",
       "169                     7.047             0.228   1.525    high  \n",
       "\n",
       "[170 rows x 2390 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def upper_bound_context_baseline(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    representation=\"info.mofid.mofid_clean\",\n",
    "    target=\"outputs.H2O-henry_coefficient-mol--kg--Pa_log_cat\",\n",
    "    target_rename_dict={\n",
    "        \"outputs.H2O-henry_coefficient-mol--kg--Pa_log_cat\": \"H2O Henry coefficient\"\n",
    "    },\n",
    "):\n",
    "    # train GPT3 directly on water\n",
    "    test_prompts = create_single_property_forward_prompts(\n",
    "        test_df,\n",
    "        target,\n",
    "        target_rename_dict,\n",
    "        representation_col=representation,\n",
    "        encode_value=False,\n",
    "    )\n",
    "\n",
    "    test_prompts = create_single_property_forward_prompts(\n",
    "        test_df,\n",
    "        target,\n",
    "        target_rename_dict,\n",
    "        representation_col=representation,\n",
    "        encode_value=False,\n",
    "    )\n",
    "\n",
    "    filename_base = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "    train_filename = f\"run_files/{filename_base}_train_prompts_mof_bl.jsonl\"\n",
    "    valid_filename = f\"run_files/{filename_base}_valid_prompts_mof_bl.jsonl\"\n",
    "\n",
    "    train_prompts.to_json(train_filename, orient=\"records\", lines=True)\n",
    "    test_prompts.to_json(valid_filename, orient=\"records\", lines=True)\n",
    "\n",
    "    modelname = fine_tune(train_filename, valid_filename)\n",
    "\n",
    "    completions = query_gpt3(modelname, test_prompts)\n",
    "    predictions = [\n",
    "        extract_prediction(completions, i) for i in range(len(completions[\"choices\"]))\n",
    "    ]\n",
    "    true = test_prompts[\"completion\"].apply(lambda x: x.split(\"@\")[0].strip())\n",
    "    cm = ConfusionMatrix(actual_vector=true.to_list(), predict_vector=predictions)\n",
    "\n",
    "    results = {\n",
    "        \"train_filename\": train_filename,\n",
    "        \"valid_filename\": valid_filename,\n",
    "        \"modelname\": modelname,\n",
    "        \"completions\": completions,\n",
    "        \"cm\": cm,\n",
    "        \"accuracy\": cm.ACC_Macro,\n",
    "        \"train_size\": len(train_df),\n",
    "        \"test_size\": len(test_df),\n",
    "        \"representation\": representation,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def lower_bound_context_baselines(\n",
    "    train_df, test_df, target=\"outputs.H2O-henry_coefficient-mol--kg--Pa_log_cat\"\n",
    "):\n",
    "    test_true = test_df[target].to_list()\n",
    "    train_true = train_df[target].to_list()\n",
    "\n",
    "    # Dummy Classifier\n",
    "    random = DummyClassifier(strategy=\"uniform\")\n",
    "    most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "    stratified = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "    random.fit(train_true, train_true)\n",
    "    most_frequent.fit(train_true, train_true)\n",
    "    stratified.fit(train_true, train_true)\n",
    "\n",
    "    random_preds = random.predict(test_true)\n",
    "    most_frequent_preds = most_frequent.predict(test_true)\n",
    "    stratified_preds = stratified.predict(test_true)\n",
    "\n",
    "    random_cm = ConfusionMatrix(actual_vector=test_true, predict_vector=random_preds)\n",
    "    most_frequent_cm = ConfusionMatrix(\n",
    "        actual_vector=test_true, predict_vector=most_frequent_preds\n",
    "    )\n",
    "    stratified_cm = ConfusionMatrix(\n",
    "        actual_vector=test_true, predict_vector=stratified_preds\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"random\": {\n",
    "            \"cm\": random_cm,\n",
    "            \"accuracy\": random_cm.ACC_Macro,\n",
    "        },\n",
    "        \"most_frequent\": {\n",
    "            \"cm\": most_frequent_cm,\n",
    "            \"accuracy\": most_frequent_cm.ACC_Macro,\n",
    "        },\n",
    "        \"stratified\": {\n",
    "            \"cm\": stratified_cm,\n",
    "            \"accuracy\": stratified_cm.ACC_Macro,\n",
    "        },\n",
    "        \"train_size\": len(train_df),\n",
    "        \"test_size\": len(test_df),\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def chemistry_encoded_context_baseline(train_df, test_df, features, train_gases, test_gases, gas_properties, random_seed=None, tune=True):\n",
    "\n",
    "    train_frame  = create_mof_w_context_frame(df=train_df, gas_frame=gas_features, gases=train_gases, gas_properties=gas_properties, features=features)\n",
    "    test_frame = create_mof_w_context_frame(df=test_df, gas_frame=gas_features, gases=test_gases, gas_properties=gas_properties, features=features)\n",
    "\n",
    "    feat = features + gas_properties\n",
    "\n",
    "    xgb = XGBClassificationBaseline(random_seed)\n",
    "    if tune:\n",
    "        xgb.tune(train_frame[feat], train_frame['target'])\n",
    "    xgb.fit(train_frame[feat], train_frame['target'])\n",
    "\n",
    "    preds = xgb.predict(test_frame[feat])\n",
    "    true = test_frame['target'].to_list()\n",
    "    cm = ConfusionMatrix(actual_vector=true, predict_vector=preds)\n",
    "    return {\n",
    "        \"cm\": cm,\n",
    "        \"accuracy\": cm.ACC_Macro,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photoswitch\n",
    "\n",
    "> Code specific for the photoswitch test case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the photoswitch datataset, we'll use a GPR on the \"fragprint\" representation using a Tanimoto kernel (as in [the original implementation](https://github.com/Ryan-Rhys/The-Photoswitch-Dataset/blob/master/property_prediction/predict_with_GPR.py))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "\n",
    "class Tanimoto(gpflow.kernels.Kernel):\n",
    "    \"\"\"Tanimoto kernel.\n",
    "\n",
    "    Taken from https://github.com/Ryan-Rhys/The-Photoswitch-Dataset/blob/master/property_prediction/kernels.py.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        :param kwargs: accepts `name` and `active_dims`, which is a list or\n",
    "            slice of indices which controls which columns of X are used (by\n",
    "            default, all columns are used).\n",
    "        \"\"\"\n",
    "        for kwarg in kwargs:\n",
    "            if kwarg not in {\"name\", \"active_dims\"}:\n",
    "                raise TypeError(\"Unknown keyword argument:\", kwarg)\n",
    "        super().__init__(**kwargs)\n",
    "        self.variance = gpflow.Parameter(1.0, transform=positive())\n",
    "\n",
    "    def K(self, X, X2=None):\n",
    "        \"\"\"\n",
    "        Compute the Tanimoto kernel matrix σ² * ((<x, y>) / (||x||^2 + ||y||^2 - <x, y>))\n",
    "        :param X: N x D array\n",
    "        :param X2: M x D array. If None, compute the N x N kernel matrix for X.\n",
    "        :return: The kernel matrix of dimension N x M\n",
    "        \"\"\"\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "\n",
    "        Xs = tf.reduce_sum(tf.square(X), axis=-1)  # Squared L2-norm of X\n",
    "        X2s = tf.reduce_sum(tf.square(X2), axis=-1)  # Squared L2-norm of X2\n",
    "        cross_product = tf.tensordot(\n",
    "            X, X2, [[-1], [-1]]\n",
    "        )  # outer product of the matrices X and X2\n",
    "\n",
    "        # Analogue of denominator in Tanimoto formula\n",
    "\n",
    "        denominator = -cross_product + broadcasting_elementwise(tf.add, Xs, X2s)\n",
    "\n",
    "        return self.variance * cross_product / denominator\n",
    "\n",
    "    def K_diag(self, X):\n",
    "        \"\"\"\n",
    "        Compute the diagonal of the N x N kernel matrix of X\n",
    "        :param X: N x D array\n",
    "        :return: N x 1 array\n",
    "        \"\"\"\n",
    "        return tf.fill(tf.shape(X)[:-1], tf.squeeze(self.variance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "def compute_morgan_fingerprints(smiles_list: Iterable[str] # list of SMILEs\n",
    ") -> np.ndarray:\n",
    "    rdkit_mols = [MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "    rdkit_smiles = [MolToSmiles(mol, isomericSmiles=False) for mol in rdkit_mols]\n",
    "    rdkit_mols = [MolFromSmiles(smiles) for smiles in rdkit_smiles]\n",
    "    X = [\n",
    "        AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=2048)\n",
    "        for mol in rdkit_mols\n",
    "    ]\n",
    "    X = np.asarray(X)\n",
    "    return X\n",
    "\n",
    "def compute_fragprints(\n",
    "    smiles_list: Iterable[str] # list of SMILEs\n",
    ") -> np.ndarray:\n",
    "    X = compute_morgan_fingerprints(smiles_list)\n",
    "\n",
    "    fragments = {d[0]: d[1] for d in Descriptors.descList[115:]}\n",
    "    X1 = np.zeros((len(smiles_list), len(fragments)))\n",
    "    for i in range(len(smiles_list)):\n",
    "        mol = MolFromSmiles(smiles_list[i])\n",
    "        try:\n",
    "            features = [fragments[d](mol) for d in fragments]\n",
    "        except:\n",
    "            raise Exception(\"molecule {}\".format(i) + \" is not canonicalised\")\n",
    "        X1[i, :] = features\n",
    "\n",
    "    X = np.concatenate((X, X1), axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_morgan_fingerprints(['C1=CC=CC=C1', 'CCC', 'CCC#N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fragprints(['C1=CC=CC=C1', 'CCC', 'CCC#N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "class GPRBaseline(BaseLineModel):\n",
    "    \"\"\"GPR w/ Tanimoto kernel baseline.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.model = None\n",
    "        self.y_scaler = StandardScaler()\n",
    "\n",
    "    def tune(\n",
    "        self,\n",
    "        X_train: np.ndarray, # N x D features\n",
    "        y_train: np.ndarray  # N x 1 target\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train: np.ndarray, # N x D features\n",
    "        y_train: np.ndarray  # N x 1 target\n",
    "    ):\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        def objective_closure():\n",
    "            return -m.log_marginal_likelihood()\n",
    "\n",
    "        y_train = self.y_scaler.fit_transform(y_train)\n",
    "\n",
    "        m = gpflow.models.GPR(\n",
    "            data=(X_train, y_train),\n",
    "            mean_function=Constant(np.mean(y_train)),\n",
    "            kernel=Tanimoto(),\n",
    "            noise_variance=1,\n",
    "        )\n",
    "\n",
    "        # Optimise the kernel variance and noise level by the marginal likelihood\n",
    "        opt = gpflow.optimizers.Scipy()\n",
    "        opt.minimize(\n",
    "            objective_closure, m.trainable_variables, options=dict(maxiter=10000)\n",
    "        )\n",
    "        print_summary(m)\n",
    "        self.model = m\n",
    "\n",
    "    def predict(\n",
    "            self, \n",
    "            X_test: np.ndarray # N x D features\n",
    "        ):  \n",
    "        y_pred, y_var = self.model.predict_f(X_test)\n",
    "        y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gpt3forchem.data import get_photoswitch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some data using \"fragprint\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_photoswitch_data()\n",
    "smiles_list = df['SMILES'].values\n",
    "y = df['E isomer pi-pi* wavelength in nm'].values\n",
    "X = compute_fragprints(smiles_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random train/test split. In the original work they use a random, unstratified split in 80/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gpt3/lib/python3.9/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "2022-09-13 13:26:43.267626: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.27311 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 39.2955  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02172 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "baseline = GPRBaseline()\n",
    "baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597867662966574"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems quite comparable to the results from the original paper (0.9 stated in the [README](https://github.com/Ryan-Rhys/The-Photoswitch-Dataset))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export \n",
    "\n",
    "def train_test_gpr_baseline(train_file, test_file, delete_from_prompt: str = 'what is the transition wavelength of', representation_column: str = 'SMILES'): \n",
    "    df = get_photoswitch_data()\n",
    "    train_frame = pd.read_json(train_file, orient=\"records\", lines=True)\n",
    "    test_frame = pd.read_json(test_file, orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "    repr_train = train_frame['repr']\n",
    "    repr_test = test_frame['repr']\n",
    "    y_train = np.array([df[df[representation_column]==smile]['E isomer pi-pi* wavelength in nm'].values[0] for smile in repr_train])\n",
    "    y_test = np.array([df[df[representation_column]==smile]['E isomer pi-pi* wavelength in nm'].values[0] for smile in repr_test])\n",
    "\n",
    "    if representation_column =='SMILES': \n",
    "        smiles_train = repr_train\n",
    "        smiles_test = repr_test\n",
    "    else: \n",
    "        smiles_train = np.array([df[df[representation_column]==smile]['SMILES'].values[0] for smile in repr_train])\n",
    "        smiles_test = np.array([df[df[representation_column]==smile]['SMILES'].values[0] for smile in repr_test]) \n",
    "\n",
    "    df_train = pd.DataFrame(\n",
    "        {\n",
    "            \"SMILES\": smiles_train,\n",
    "            'y': y_train\n",
    "        }\n",
    "    )\n",
    "    df_test = pd.DataFrame(\n",
    "        {\n",
    "            \"SMILES\": smiles_test,\n",
    "            'y': y_test\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_train = df_train.drop_duplicates(subset=['SMILES'])\n",
    "    df_test = df_test.drop_duplicates(subset=['SMILES'])\n",
    "\n",
    "    X_train = compute_fragprints(df_train['SMILES'].values)\n",
    "    X_test = compute_fragprints(df_test['SMILES'].values)\n",
    "\n",
    "    baseline = GPRBaseline()\n",
    "    baseline.fit(X_train, df_train['y'].values)\n",
    "\n",
    "    predictions = baseline.predict(X_test)\n",
    "\n",
    "    _, bins = pd.cut(df['E isomer pi-pi* wavelength in nm'], 5, retbins=True)\n",
    "\n",
    "    # we clip as out-of-bound predictions result in NaNs\n",
    "    pred = np.clip(predictions.flatten(), a_min=bins[0], a_max=bins[-1])\n",
    "    predicted_bins = pd.cut(pred, bins, labels=np.arange(5), include_lowest=True)\n",
    "    true_bins = pd.cut(df_test['y'].values.flatten(), bins, labels=np.arange(5))\n",
    "\n",
    "    cm = ConfusionMatrix(true_bins.astype(int), predicted_bins.astype(int))\n",
    "\n",
    "    return {\n",
    "        'true_bins': true_bins,\n",
    "        'predicted_bins': predicted_bins,\n",
    "        'cm': cm,\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_gpr_baseline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
