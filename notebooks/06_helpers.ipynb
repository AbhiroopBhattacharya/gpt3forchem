{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from functools import lru_cache\n",
    "from hashlib import sha256\n",
    "from typing import Callable, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.util import hash_pandas_object\n",
    "from pycm import ConfusionMatrix\n",
    "from scipy.stats import mode\n",
    "\n",
    "from gpt3forchem.input import encode_categorical_value\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# taken from https://gist.github.com/dsevero/3f3db7acb45d6cd8e945e8a32eaca168\n",
    "class HashableDataFrame(pd.DataFrame):\n",
    "    def __init__(self, obj):\n",
    "        super().__init__(obj)\n",
    "\n",
    "    def __hash__(self):\n",
    "        hash_value = sha256(hash_pandas_object(self, index=True).values)\n",
    "        hash_value = hash(hash_value.hexdigest())\n",
    "        return hash_value\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.equals(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt3forchem.data import get_photoswitch_data\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a cached function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def cached_function(df): \n",
    "    return df['Extinction'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_photoswitch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HashableDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336213.03"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_function(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# taken from https://github.com/IBM/UQ360/blob/main/uq360/metrics/regression_metrics.py\n",
    "def picp(y_true, y_lower, y_upper):\n",
    "    \"\"\"\n",
    "    Prediction Interval Coverage Probability (PICP). Computes the fraction of samples for which the grounds truth lies\n",
    "    within predicted interval. Measures the prediction interval calibration for regression.\n",
    "    Args:\n",
    "        y_true: Ground truth\n",
    "        y_lower: predicted lower bound\n",
    "        y_upper: predicted upper bound\n",
    "    Returns:\n",
    "        float: the fraction of samples for which the grounds truth lies within predicted interval.\n",
    "    \"\"\"\n",
    "    satisfies_upper_bound = y_true <= y_upper\n",
    "    satisfies_lower_bound = y_true >= y_lower\n",
    "    return np.mean(satisfies_upper_bound * satisfies_lower_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picp(np.array([1, 2, 3]), np.array([0, 1, 2]), np.array([2, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use test-time augmentation for classification we predict one class label per augmented example. A handwavy way of converting this to multiclass probabilities, would be to just get the frequency of the occurance of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prediction_frame = pd.DataFrame(\n",
    "    {\n",
    "        'y_true': [1] * 10 + [2] * 10 + [3] * 10,\n",
    "        'repr': ['a'] * 10 + ['b'] * 10 + ['c'] * 10,\n",
    "        'y_pred': [1, 1, 2, 3, 1, 1, 1, 2, 4, 1] + [2, 2, 2, 2, 2, 2, 2, 2, 2, 2] + [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
    "    }) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>repr</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true repr  y_pred\n",
       "0        1    a       1\n",
       "1        1    a       1\n",
       "2        1    a       2\n",
       "3        1    a       3\n",
       "4        1    a       1\n",
       "5        1    a       1\n",
       "6        1    a       1\n",
       "7        1    a       2\n",
       "8        1    a       4\n",
       "9        1    a       1\n",
       "10       2    b       2\n",
       "11       2    b       2\n",
       "12       2    b       2\n",
       "13       2    b       2\n",
       "14       2    b       2\n",
       "15       2    b       2\n",
       "16       2    b       2\n",
       "17       2    b       2\n",
       "18       2    b       2\n",
       "19       2    b       2\n",
       "20       3    c       3\n",
       "21       3    c       3\n",
       "22       3    c       3\n",
       "23       3    c       3\n",
       "24       3    c       3\n",
       "25       3    c       3\n",
       "26       3    c       3\n",
       "27       3    c       3\n",
       "28       3    c       3\n",
       "29       3    c       3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prediction_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the multiclass vote we create with test-time augmentation or ensemble models to \"multiclass probabilities\" by computing the frequency of every class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def multiclass_vote_to_probabilities(\n",
    "        prediction_frame: pd.DataFrame, # input dataframe with predictions and representations\n",
    "        prediction_colum: str, # name of the column with predictions\n",
    "        representation_column: str, # name of the column with representations\n",
    "        classes: Optional[Iterable]=None # names of all possible classes\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "    if classes is None: \n",
    "        classes = np.arange(5)\n",
    "    new_frame = []\n",
    "    reprs = prediction_frame[representation_column].unique()\n",
    "    for repr in reprs:\n",
    "        repr_frame = prediction_frame[prediction_frame[representation_column] == repr]\n",
    "        value_counts = dict(repr_frame[prediction_colum].value_counts())\n",
    "        frequencies = {}\n",
    "        for class_ in classes:\n",
    "            try:\n",
    "                frequencies[class_] = value_counts.get(class_, 0) / len(repr_frame)\n",
    "            except KeyError:\n",
    "                frequencies[class_] = 0\n",
    "            except ZeroDivisionError:\n",
    "                frequencies[class_] = 0 \n",
    "\n",
    "        frequencies[representation_column] = repr\n",
    "        new_frame.append(frequencies)\n",
    "    \n",
    "    return pd.DataFrame(new_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>repr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4 repr\n",
       "0  0.0  0.6  0.2  0.1  0.1    a\n",
       "1  0.0  0.0  1.0  0.0  0.0    b\n",
       "2  0.0  0.0  0.0  1.0  0.0    c"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities = multiclass_vote_to_probabilities(example_prediction_frame, 'y_pred', 'repr')\n",
    "class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert class_probabilities[class_probabilities['repr'] == 'b'][0].values[0] == 0\n",
    "assert class_probabilities[class_probabilities['repr'] == 'b'][1].values[0] == 0\n",
    "assert class_probabilities[class_probabilities['repr'] == 'b'][2].values[0] == 1\n",
    "assert class_probabilities[class_probabilities['repr'] == 'b'][3].values[0] == 0\n",
    "assert class_probabilities[class_probabilities['repr'] == 'b'][4].values[0] == 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract a numpy array in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.6, 0.2, 0.1, 0.1],\n",
       "       [0. , 0. , 1. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 1. , 0. ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities[np.arange(5)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this array to compute classification scores, e.g., the Brier score or the expected calibration error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\underset{\\hat{P}}{\\mathbb{E}}[\\left|\\mathbb{P}(\\hat{Y}=Y \\mid \\hat{P}=p)-p\\right|]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# code taken from https://github.com/IBM/UQ360/blob/main/uq360/metrics/classification_metrics.py as having the tensorflow dependency is annoying\n",
    "# The original LICENSE\n",
    "#                               Apache License\n",
    "#                         Version 2.0, January 2004\n",
    "#                      http://www.apache.org/licenses/\n",
    "\n",
    "# TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
    "\n",
    "# 1. Definitions.\n",
    "\n",
    "#    \"License\" shall mean the terms and conditions for use, reproduction,\n",
    "#    and distribution as defined by Sections 1 through 9 of this document.\n",
    "\n",
    "#    \"Licensor\" shall mean the copyright owner or entity authorized by\n",
    "#    the copyright owner that is granting the License.\n",
    "\n",
    "#    \"Legal Entity\" shall mean the union of the acting entity and all\n",
    "#    other entities that control, are controlled by, or are under common\n",
    "#    control with that entity. For the purposes of this definition,\n",
    "#    \"control\" means (i) the power, direct or indirect, to cause the\n",
    "#    direction or management of such entity, whether by contract or\n",
    "#    otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
    "#    outstanding shares, or (iii) beneficial ownership of such entity.\n",
    "\n",
    "#    \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
    "#    exercising permissions granted by this License.\n",
    "\n",
    "#    \"Source\" form shall mean the preferred form for making modifications,\n",
    "#    including but not limited to software source code, documentation\n",
    "#    source, and configuration files.\n",
    "\n",
    "#    \"Object\" form shall mean any form resulting from mechanical\n",
    "#    transformation or translation of a Source form, including but\n",
    "#    not limited to compiled object code, generated documentation,\n",
    "#    and conversions to other media types.\n",
    "\n",
    "#    \"Work\" shall mean the work of authorship, whether in Source or\n",
    "#    Object form, made available under the License, as indicated by a\n",
    "#    copyright notice that is included in or attached to the work\n",
    "#    (an example is provided in the Appendix below).\n",
    "\n",
    "#    \"Derivative Works\" shall mean any work, whether in Source or Object\n",
    "#    form, that is based on (or derived from) the Work and for which the\n",
    "#    editorial revisions, annotations, elaborations, or other modifications\n",
    "#    represent, as a whole, an original work of authorship. For the purposes\n",
    "#    of this License, Derivative Works shall not include works that remain\n",
    "#    separable from, or merely link (or bind by name) to the interfaces of,\n",
    "#    the Work and Derivative Works thereof.\n",
    "\n",
    "#    \"Contribution\" shall mean any work of authorship, including\n",
    "#    the original version of the Work and any modifications or additions\n",
    "#    to that Work or Derivative Works thereof, that is intentionally\n",
    "#    submitted to Licensor for inclusion in the Work by the copyright owner\n",
    "#    or by an individual or Legal Entity authorized to submit on behalf of\n",
    "#    the copyright owner. For the purposes of this definition, \"submitted\"\n",
    "#    means any form of electronic, verbal, or written communication sent\n",
    "#    to the Licensor or its representatives, including but not limited to\n",
    "#    communication on electronic mailing lists, source code control systems,\n",
    "#    and issue tracking systems that are managed by, or on behalf of, the\n",
    "#    Licensor for the purpose of discussing and improving the Work, but\n",
    "#    excluding communication that is conspicuously marked or otherwise\n",
    "#    designated in writing by the copyright owner as \"Not a Contribution.\"\n",
    "\n",
    "#    \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
    "#    on behalf of whom a Contribution has been received by Licensor and\n",
    "#    subsequently incorporated within the Work.\n",
    "\n",
    "# 2. Grant of Copyright License. Subject to the terms and conditions of\n",
    "#    this License, each Contributor hereby grants to You a perpetual,\n",
    "#    worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
    "#    copyright license to reproduce, prepare Derivative Works of,\n",
    "#    publicly display, publicly perform, sublicense, and distribute the\n",
    "#    Work and such Derivative Works in Source or Object form.\n",
    "\n",
    "# 3. Grant of Patent License. Subject to the terms and conditions of\n",
    "#    this License, each Contributor hereby grants to You a perpetual,\n",
    "#    worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
    "#    (except as stated in this section) patent license to make, have made,\n",
    "#    use, offer to sell, sell, import, and otherwise transfer the Work,\n",
    "#    where such license applies only to those patent claims licensable\n",
    "#    by such Contributor that are necessarily infringed by their\n",
    "#    Contribution(s) alone or by combination of their Contribution(s)\n",
    "#    with the Work to which such Contribution(s) was submitted. If You\n",
    "#    institute patent litigation against any entity (including a\n",
    "#    cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
    "#    or a Contribution incorporated within the Work constitutes direct\n",
    "#    or contributory patent infringement, then any patent licenses\n",
    "#    granted to You under this License for that Work shall terminate\n",
    "#    as of the date such litigation is filed.\n",
    "\n",
    "# 4. Redistribution. You may reproduce and distribute copies of the\n",
    "#    Work or Derivative Works thereof in any medium, with or without\n",
    "#    modifications, and in Source or Object form, provided that You\n",
    "#    meet the following conditions:\n",
    "\n",
    "#    (a) You must give any other recipients of the Work or\n",
    "#        Derivative Works a copy of this License; and\n",
    "\n",
    "#    (b) You must cause any modified files to carry prominent notices\n",
    "#        stating that You changed the files; and\n",
    "\n",
    "#    (c) You must retain, in the Source form of any Derivative Works\n",
    "#        that You distribute, all copyright, patent, trademark, and\n",
    "#        attribution notices from the Source form of the Work,\n",
    "#        excluding those notices that do not pertain to any part of\n",
    "#        the Derivative Works; and\n",
    "\n",
    "#    (d) If the Work includes a \"NOTICE\" text file as part of its\n",
    "#        distribution, then any Derivative Works that You distribute must\n",
    "#        include a readable copy of the attribution notices contained\n",
    "#        within such NOTICE file, excluding those notices that do not\n",
    "#        pertain to any part of the Derivative Works, in at least one\n",
    "#        of the following places: within a NOTICE text file distributed\n",
    "#        as part of the Derivative Works; within the Source form or\n",
    "#        documentation, if provided along with the Derivative Works; or,\n",
    "#        within a display generated by the Derivative Works, if and\n",
    "#        wherever such third-party notices normally appear. The contents\n",
    "#        of the NOTICE file are for informational purposes only and\n",
    "#        do not modify the License. You may add Your own attribution\n",
    "#        notices within Derivative Works that You distribute, alongside\n",
    "#        or as an addendum to the NOTICE text from the Work, provided\n",
    "#        that such additional attribution notices cannot be construed\n",
    "#        as modifying the License.\n",
    "\n",
    "#    You may add Your own copyright statement to Your modifications and\n",
    "#    may provide additional or different license terms and conditions\n",
    "#    for use, reproduction, or distribution of Your modifications, or\n",
    "#    for any such Derivative Works as a whole, provided Your use,\n",
    "#    reproduction, and distribution of the Work otherwise complies with\n",
    "#    the conditions stated in this License.\n",
    "\n",
    "# 5. Submission of Contributions. Unless You explicitly state otherwise,\n",
    "#    any Contribution intentionally submitted for inclusion in the Work\n",
    "#    by You to the Licensor shall be under the terms and conditions of\n",
    "#    this License, without any additional terms or conditions.\n",
    "#    Notwithstanding the above, nothing herein shall supersede or modify\n",
    "#    the terms of any separate license agreement you may have executed\n",
    "#    with Licensor regarding such Contributions.\n",
    "\n",
    "# 6. Trademarks. This License does not grant permission to use the trade\n",
    "#    names, trademarks, service marks, or product names of the Licensor,\n",
    "#    except as required for reasonable and customary use in describing the\n",
    "#    origin of the Work and reproducing the content of the NOTICE file.\n",
    "\n",
    "# 7. Disclaimer of Warranty. Unless required by applicable law or\n",
    "#    agreed to in writing, Licensor provides the Work (and each\n",
    "#    Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "#    implied, including, without limitation, any warranties or conditions\n",
    "#    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
    "#    PARTICULAR PURPOSE. You are solely responsible for determining the\n",
    "#    appropriateness of using or redistributing the Work and assume any\n",
    "#    risks associated with Your exercise of permissions under this License.\n",
    "\n",
    "# 8. Limitation of Liability. In no event and under no legal theory,\n",
    "#    whether in tort (including negligence), contract, or otherwise,\n",
    "#    unless required by applicable law (such as deliberate and grossly\n",
    "#    negligent acts) or agreed to in writing, shall any Contributor be\n",
    "#    liable to You for damages, including any direct, indirect, special,\n",
    "#    incidental, or consequential damages of any character arising as a\n",
    "#    result of this License or out of the use or inability to use the\n",
    "#    Work (including but not limited to damages for loss of goodwill,\n",
    "#    work stoppage, computer failure or malfunction, or any and all\n",
    "#    other commercial damages or losses), even if such Contributor\n",
    "#    has been advised of the possibility of such damages.\n",
    "\n",
    "# 9. Accepting Warranty or Additional Liability. While redistributing\n",
    "#    the Work or Derivative Works thereof, You may choose to offer,\n",
    "#    and charge a fee for, acceptance of support, warranty, indemnity,\n",
    "#    or other liability obligations and/or rights consistent with this\n",
    "#    License. However, in accepting such obligations, You may act only\n",
    "#    on Your own behalf and on Your sole responsibility, not on behalf\n",
    "#    of any other Contributor, and only if You agree to indemnify,\n",
    "#    defend, and hold each Contributor harmless for any liability\n",
    "#    incurred by, or claims asserted against, such Contributor by reason\n",
    "#    of your accepting any such warranty or additional liability.\n",
    "\n",
    "# END OF TERMS AND CONDITIONS\n",
    "\n",
    "# APPENDIX: How to apply the Apache License to your work.\n",
    "\n",
    "#    To apply the Apache License to your work, attach the following\n",
    "#    boilerplate notice, with the fields enclosed by brackets \"[]\"\n",
    "#    replaced with your own identifying information. (Don't include\n",
    "#    the brackets!)  The text should be enclosed in the appropriate\n",
    "#    comment syntax for the file format. We also recommend that a\n",
    "#    file or class name and description of purpose be included on the\n",
    "#    same \"printed page\" as the copyright notice for easier\n",
    "#    identification within third-party archives.\n",
    "\n",
    "# Copyright [yyyy] [name of copyright owner]\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "def multiclass_brier_score(y_true, y_prob):\n",
    "    \"\"\"Brier score for multi-class.\n",
    "\n",
    "    Args:\n",
    "        y_true: array-like of shape (n_samples,)\n",
    "            ground truth labels.\n",
    "        y_prob: array-like of shape (n_samples, n_classes).\n",
    "            Probability scores from the base model.\n",
    "    Returns:\n",
    "        float: Brier score.\n",
    "    \"\"\"\n",
    "    assert len(y_prob.shape) > 1, \"y_prob should be array-like of shape (n_samples, n_classes)\"\n",
    "\n",
    "    y_target = np.zeros_like(y_prob)\n",
    "    y_target[np.arange(y_true.size), y_true] = 1.0\n",
    "    return np.mean(np.sum((y_target - y_prob) ** 2, axis=1))\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, y_pred=None, num_bins=10, return_counts=False):\n",
    "    \"\"\" Computes the reliability curve and the  expected calibration error [1]_ .\n",
    "\n",
    "    References:\n",
    "        .. [1] Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q. Weinberger; Proceedings of the 34th International Conference\n",
    "            on Machine Learning, PMLR 70:1321-1330, 2017.\n",
    "\n",
    "    The expected calibration error is the difference in expectation between the confidence and accuracy. \n",
    "\n",
    "    Args:\n",
    "        y_true: array-like of shape (n_samples,)\n",
    "            ground truth labels.\n",
    "        y_prob: array-like of shape (n_samples, n_classes).\n",
    "            Probability scores from the base model.\n",
    "        y_pred: array-like of shape (n_samples,)\n",
    "            predicted labels.\n",
    "        num_bins: number of bins.\n",
    "        return_counts: set to True to return counts also.\n",
    "\n",
    "    Returns:\n",
    "        float or tuple:\n",
    "            - ece (float): expected calibration error.\n",
    "            - confidences_in_bins: average confidence in each bin (returned only if return_counts is True).\n",
    "            - accuracies_in_bins: accuracy in each bin (returned only if return_counts is True).\n",
    "            - frac_samples_in_bins: fraction of samples in each bin (returned only if return_counts is True).\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(y_prob.shape) > 1, \"y_prob should be array-like of shape (n_samples, n_classes)\"\n",
    "    num_samples, num_classes = y_prob.shape\n",
    "    top_scores = np.max(y_prob, axis=1)\n",
    "\n",
    "    if y_pred is None:\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    if num_classes == 2:\n",
    "        bins_edges = np.histogram_bin_edges([], bins=num_bins, range=(0.5, 1.0))\n",
    "    else:\n",
    "        bins_edges = np.histogram_bin_edges([], bins=num_bins, range=(0.0, 1.0))\n",
    "\n",
    "    non_boundary_bin_edges = bins_edges[1:-1]\n",
    "    bin_centers = (bins_edges[1:] + bins_edges[:-1])/2\n",
    "\n",
    "    sample_bin_ids = np.digitize(top_scores, non_boundary_bin_edges)\n",
    "\n",
    "    num_samples_in_bins = np.zeros(num_bins)\n",
    "    accuracies_in_bins = np.zeros(num_bins)\n",
    "    confidences_in_bins = np.zeros(num_bins)\n",
    "\n",
    "    for bin in range(num_bins):\n",
    "        num_samples_in_bins[bin] = len(y_pred[sample_bin_ids == bin])\n",
    "        if num_samples_in_bins[bin] > 0:\n",
    "            accuracies_in_bins[bin] = np.sum(y_true[sample_bin_ids == bin] == y_pred[sample_bin_ids == bin]) / num_samples_in_bins[bin]\n",
    "            confidences_in_bins[bin] = np.sum(top_scores[sample_bin_ids == bin]) / num_samples_in_bins[bin]\n",
    "\n",
    "    ece = np.sum(\n",
    "        num_samples_in_bins * np.abs(accuracies_in_bins - confidences_in_bins) / num_samples\n",
    "    )\n",
    "    frac_samples_in_bins = num_samples_in_bins / num_samples\n",
    "\n",
    "    if not return_counts:\n",
    "        return ece\n",
    "    else:\n",
    "        return ece, confidences_in_bins, accuracies_in_bins, frac_samples_in_bins, bin_centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07333333333333335"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_brier_score(example_prediction_frame.groupby('repr').mean()['y_true'].values.astype(int), class_probabilities[np.arange(5)].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is the best Brier score, 1 is the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_calibration_error(example_prediction_frame.groupby('repr').mean()['y_true'].values.astype(int), class_probabilities[np.arange(5)].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a wrapper that orchestrates the whole process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to convert potential string labels into numerical ones and then compute both metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def only_mode(x):\n",
    "    return mode(x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def augmented_classification_scores(repr, true, predictions, cat_encode_func: Optional[Callable]=encode_categorical_value, class_names=np.arange(5)): \n",
    "    augmented_predictions = pd.DataFrame(\n",
    "        {\n",
    "            'repr': repr,\n",
    "            'true': true,\n",
    "            'predictions': predictions,\n",
    "        })\n",
    "\n",
    "    if cat_encode_func is not None:\n",
    "        augmented_predictions['true'] = augmented_predictions['true'].apply(cat_encode_func)\n",
    "        augmented_predictions['predictions'] = augmented_predictions['predictions'].apply(cat_encode_func)\n",
    "\n",
    "    predictions_augmented = augmented_predictions.groupby('repr').agg(['mean', 'std', only_mode])\n",
    "\n",
    "    cm = ConfusionMatrix(\n",
    "        predictions_augmented['true']['only_mode'].values,\n",
    "        predictions_augmented['predictions']['only_mode'].values,\n",
    "    )\n",
    "\n",
    "    class_probablities = multiclass_vote_to_probabilities(augmented_predictions, 'predictions', 'repr')\n",
    "\n",
    "    brier_score = multiclass_brier_score(augmented_predictions.groupby('repr').mean()['true'].values.astype(int), class_probablities[class_names].values)\n",
    "\n",
    "    ece = expected_calibration_error(augmented_predictions.groupby('repr').mean()['true'].values.astype(int), class_probablities[class_names].values)\n",
    "\n",
    "    return cm, brier_score, ece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_43744/3203171969.py:2: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return mode(x)[0][0]\n",
      "/var/folders/m9/_txh68y946s4pxy1x2wnd3lh0000gn/T/ipykernel_43744/3203171969.py:2: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return mode(x)[0][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(pycm.ConfusionMatrix(classes: [1, 2, 3]),\n",
       " 0.07333333333333335,\n",
       " 0.13333333333333333)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_classification_scores(example_prediction_frame['repr'], example_prediction_frame['y_true'], example_prediction_frame['y_pred'], cat_encode_func=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def make_if_not_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.5, 3.334149410386609, 7.665850589613391)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "\n",
    "def get_else_nan(x, key):\n",
    "    if isinstance(x, dict):\n",
    "        try:\n",
    "            return x[key]\n",
    "        except KeyError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        try:\n",
    "            return getattr(x, key)\n",
    "        except AttributeError:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'a': 1, 'b': 2, 'c': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_else_nan(test_dict, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_else_nan(test_dict, 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestClass:\n",
    "    def __init__(self, a, b, c):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "\n",
    "test_object = TestClass(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_else_nan(test_object, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_else_nan(test_object, 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpt3')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
